
# QueerBench

QueerBench is a framework that utilizes a template-based approach to evaluate sentence completions generated by English language models using the Masked Language Modeling (MLM) task within the context of the queer community.

Archive content:

    .
    └── QueerBench/
    ├── data/
    │   ├── evaluation/
    │   ├── prediction/
    │   ├── queer_identities/
    │   │   ├── pronouns.csv
    │   │   └── terms.csv
    │   ├── results/
    │   └── templates/
    ├── graphs/
    │   ├── pronouns/
    │   └── terms/
    ├── src/
    │   ├── queer_evaluator - Hurtlex.ipynb
    │   ├── queer_evaluator - Perspective.ipynb
    │   ├── queer_evaluator - Afinn.ipynb
    │   ├── queer_graph.ipynb
    │   ├── queer_results.ipynb
    │   └── template_builder.ipynb
    └── README.md

Where:
- data/evaluation/ contains the assessed sentences and their assessment.
- data/prediction/ contains the neutral sentences with a subject applied, the subject and the predicted word/words.
- data/queer_identities/ contains the two .csv files that contain pronouns and terms used in the framework.
- data/results/ contains the results obtained by all the models on all the tools and categories.
- data/template/ contains two .csv files, template.csv contains the natural sentences and template_complete.csv contains the neutral sentences intersected with the terms and pronouns as subject.
- graphs/pronouns/ contains the graphs as .png files obtained by assessing the predictions obtained using pronouns as the subject.
- graphs/terms/ contains the graphs as .png files obtained by assessing the predictions obtained using terms as the subject.
- src/queer_evaluator - Hurtlex.ipynb contains the functions used to obtain HurtLex assessments.
- src/queer_evaluator - Perspective.ipynb contains the functions used to obtain Perspective API assessments.
- src/queer_evaluator - Sentiment Analysis.ipynb contains the functions used to obtain AFINN assessments.
- src/queer_graph.ipynb contains the functions used to generate the graphs.
- src/queer_results.ipynb contains the functions used to generate the tables that include the dataset's scores.
- src/template_builder.ipynb contains the functions used to generate the dataset

## Running Tests

1. To run tests, create the dataset running the code in template_builder.ipynb using the following pattern.
Input: model, number of predictions

Example: 
```python
    TemplatePrediction(BERTTWEET_LARGE, 5)
```
2. To assess the dataset use the three files: 
- queer_evaluator - Hurtlex.ipynb
- queer_evaluator - Perspective.ipynb
- queer_evaluator - Sentiment Analysis.ipynb

In each file given as input: input file path, template, output file path

Example:
```python
    QueerEvaluator(EVALUATION_PATH, BERTWEET_LARGE_TEMPLATE_1, EVALUATION_PATH)
```
3. Run the functions in queer_results.ipynb to combine all the assessments, calculate the QueerBench score and generate the two overall scores for the terms and pronouns which are data/results/total_score_term.csv and data/results/total_score_pronouns.csv correspondingly.

4. Use the functions in queer_graph.ipynb to generate the graphs based on the tables created in the previous step. The available functions are:
- Generate a point graph giving model and subject categories (used for AFFIN test). 
Example:
```python
error_bar(BERTWEET_MODELS, PRONOUN)
```
- Generate a line and bar graph (used for Perspective test). 
Example:
```python
perspective_linebar(perspective_linebar(ROBERTA_MODELS, PRONOUN))
```
- Generate a line and bar graph (used for Perspective test). 
Example:
```python
hurtlex_linebar(MODELS, TERM))
```
- Generate two heat maps based on the pronouns and terms scores. The boolean in input allows us to obtain either a full or a partial graph.
```python
term_graph_score(False)
pronouns_graph_score(False)
```


