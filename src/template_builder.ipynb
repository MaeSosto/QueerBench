{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoModelForCausalLM , AutoTokenizer, pipeline, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertModel, AlbertForMaskedLM\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from afinn import Afinn\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "from time import sleep\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAC Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTITIES = 'identities'\n",
    "ORIENTATION = 'orientation'\n",
    "OTHER = 'other'\n",
    "PRONOUNS = 'pronouns'\n",
    "MASKBERT_ = '\\[MASK\\]'\n",
    "MASKBERT= '[MASK]'\n",
    "MASKROBERT = '<mask>'\n",
    "TARGET = '<target>'\n",
    "NOM = '<nom>'\n",
    "POSDEP = '<pos_dep>'\n",
    "ACC = '<acc>'\n",
    "BE = '<be>'\n",
    "QUEER = 'queer'\n",
    "NONQUEER = 'non-queer'\n",
    "\n",
    "#TEMPLATES\n",
    "TEMPLATE_NOZZA = '../src/templates/template_nozza.csv'\n",
    "TEMPLATE_NOZZA_COMPLETE = '../src/templates/template_nozza_complete.csv'\n",
    "TEMPLATE_TOXIC2 = '../src/templates/template_toxic2.csv'\n",
    "TEMPLATE_TOXIC2_COMPLETE = '../src/templates/template_toxic2_complete.csv'\n",
    "TEMPLATE_TOXIC1 = '../src/templates/template_toxic1.csv'\n",
    "TEMPLATE_TOXIC1_COMPLETE = '../src/templates/template_toxic1_complete.csv'\n",
    "TEMPLATE_TOXIC1_CHUNK = '../src/templates/toxic1/template_toxic1'\n",
    "TEMPLATE_TOXIC2_CHUNK = '../src/templates/toxic2/template_toxic2'\n",
    "\n",
    "#IDENTITIES CSV\n",
    "IDENTITIES_CSV = '../src/templates/queer_identities/identities.csv'\n",
    "PRONOUNS_CSV = '../src/templates/queer_identities/pronouns.csv'\n",
    "\n",
    "#MODELS\n",
    "BERT_BASE = 'bert-base-uncased'\n",
    "BERT_LARGE = 'bert-large-uncased'\n",
    "ROBERTA_BASE = 'roberta-base'\n",
    "ROBERTA_LARGE = 'roberta-large'\n",
    "GPT2 = 'gpt2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Builder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateBuilder():\n",
    "    def __init__(self, template_path):\n",
    "        self.data = []\n",
    "        self.template_path = template_path\n",
    "        self.template_file = pd.read_csv(template_path, sep=\";\")\n",
    "        self.template_identities = pd.read_csv(IDENTITIES_CSV, sep=';')\n",
    "        self.template_pronouns = pd.read_csv(PRONOUNS_CSV, sep=';')\n",
    "        self.template_builder()\n",
    "    \n",
    "\n",
    "    def read_csv(self):\n",
    "        if self.template_path == TEMPLATE_NOZZA:\n",
    "            df = pd.read_csv(self.template_path, sep=\";\", dtype={'template': 'category', 'type': 'category'})\n",
    "        else:\n",
    "            if self.template_path == TEMPLATE_TOXIC1 or self.template_path == TEMPLATE_TOXIC2:\n",
    "                df = pd.read_csv(self.template_path, sep=\";\", dtype={'template': 'category'})\n",
    "        return df\n",
    "\n",
    "    def template_builder(self):\n",
    "        if(self.template_path == TEMPLATE_NOZZA):\n",
    "            self.template_nozza()\n",
    "        else:\n",
    "            if (self.template_path == TEMPLATE_TOXIC1):\n",
    "                self.template_toxic1()\n",
    "            else: \n",
    "                self.template_toxic2()\n",
    "        \n",
    "    def template_nozza(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, r in self.template_identities.iterrows():\n",
    "                _sentence = re.sub(TARGET, f\"The {r.loc['identity']} person\", sentence)\n",
    "                _sentence = re.sub(BE, 'is', _sentence)\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[\"identity\"], #identity\n",
    "                    r.loc[\"type\"] #type identity\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "            for ind, r in self.template_pronouns.iterrows():\n",
    "                _sentence = re.sub(TARGET, r.loc[\"nom\"], sentence)\n",
    "                _sentence = re.sub(BE, r.loc[\"be\"], _sentence)\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[\"nom\"], #identity\n",
    "                    r.loc[\"type\"], #type identity\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"new_template\", \"identity\", \"type\"])\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "        data_df.to_csv(TEMPLATE_NOZZA_COMPLETE, sep=';')\n",
    "        \n",
    "    def template_toxic1(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, identity in self.template_identities.iterrows():\n",
    "                _sentence = re.sub(TARGET, f\"The {identity.loc['identity']} person\", sentence)\n",
    "                for id, pronouns in self.template_pronouns.iterrows():\n",
    "                    __sentence = re.sub(NOM, pronouns.loc['nom'], _sentence)\n",
    "                    __sentence = re.sub(BE, pronouns.loc['be'], __sentence)\n",
    "                    data=[\n",
    "                        #sentence, #template\n",
    "                        __sentence, #new template\n",
    "                        identity.loc[\"identity\"], #identity\n",
    "                        identity.loc[\"type\"], #type identity\n",
    "                        pronouns.loc[\"nom\"], #pronouns nom\n",
    "                        pronouns.loc[\"type\"] #type pronouns\n",
    "                    ]\n",
    "                    dataList.append(data) \n",
    "            for ind, pronouns in self.template_pronouns.iterrows():\n",
    "                _sentence = re.sub(TARGET, pronouns.loc[\"nom\"], sentence)\n",
    "                _sentence = re.sub(BE, pronouns.loc[\"be\"], _sentence)\n",
    "                _sentence = re.sub(NOM, pronouns.loc[\"nom\"], _sentence)\n",
    "                data=[\n",
    "                    #sentence, #template\n",
    "                    _sentence, #new template\n",
    "                    pronouns.loc[\"nom\"], #identity\n",
    "                    pronouns.loc[\"type\"], #type identity\n",
    "                    pronouns.loc[\"nom\"], #pronouns nom\n",
    "                    pronouns.loc[\"type\"] #type pronouns\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"new_template\", \"identity\", \"type_identity\", \"pronoun\", \"pronouns_type\"])\n",
    "        data_df['new_template'] = data_df['new_template'].astype('category')\n",
    "        data_df['identity'] = data_df['identity'].astype('category')\n",
    "        data_df['type_identity'] = data_df['type_identity'].astype('category')\n",
    "        data_df['pronoun'] = data_df['pronoun'].astype('category')\n",
    "        data_df['pronouns_type'] = data_df['pronouns_type'].astype('category')\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "        data_df.to_csv(TEMPLATE_TOXIC1_COMPLETE, sep=';')\n",
    "        for i,chunk in tqdm(enumerate(pd.read_csv(TEMPLATE_TOXIC1_COMPLETE, chunksize=500000, sep=';',  dtype={'new_template':'category', 'identity': 'category', 'type_identity': 'category','pronoun': 'category', 'pronouns_type': 'category'})), total=20, desc='Creating chunks', unit='chunks'):\n",
    "            chunk.to_csv(TEMPLATE_TOXIC1_CHUNK+'_chunk{}.csv'.format(i), index=False, sep=';')\n",
    "\n",
    "    def template_toxic2(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, identity in self.template_identities.iterrows():\n",
    "                _sentence = re.sub(TARGET, f\"The {identity.loc['identity']} person\", sentence)\n",
    "                for id, pronouns in self.template_pronouns.iterrows():\n",
    "                    __sentence = re.sub(POSDEP, pronouns.loc['pos_dep'], _sentence)\n",
    "                    __sentence = re.sub(BE, pronouns.loc['be'], __sentence)\n",
    "                    data=[\n",
    "                        #sentence, #template\n",
    "                        __sentence, #new template\n",
    "                        identity.loc[\"identity\"], #identity\n",
    "                        identity.loc[\"type\"], #type identity\n",
    "                        pronouns.loc[\"nom\"], #pronouns nom\n",
    "                        pronouns.loc[\"type\"] #type pronouns\n",
    "                    ]\n",
    "                    dataList.append(data) \n",
    "            for ind, pronouns in self.template_pronouns.iterrows():\n",
    "                _sentence = re.sub(TARGET, pronouns.loc[\"nom\"], sentence)\n",
    "                _sentence = re.sub(BE, pronouns.loc[\"be\"], _sentence)\n",
    "                _sentence = re.sub(POSDEP, pronouns.loc['pos_dep'], _sentence)\n",
    "                data=[\n",
    "                    #sentence, #template\n",
    "                    _sentence, #new template\n",
    "                    pronouns.loc[\"nom\"], #identity\n",
    "                    pronouns.loc[\"type\"], #type identity\n",
    "                    pronouns.loc[\"nom\"], #pronouns nom\n",
    "                    pronouns.loc[\"type\"] #type pronouns\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"new_template\", \"identity\", \"type_identity\", \"pronoun\", \"pronouns_type\"])\n",
    "        data_df['new_template'] = data_df['new_template'].astype('category')\n",
    "        data_df['identity'] = data_df['identity'].astype('category')\n",
    "        data_df['type_identity'] = data_df['type_identity'].astype('category')\n",
    "        data_df['pronoun'] = data_df['pronoun'].astype('category')\n",
    "        data_df['pronouns_type'] = data_df['pronouns_type'].astype('category')\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "        data_df.to_csv(TEMPLATE_TOXIC2_COMPLETE)\n",
    "        for i,chunk in tqdm(enumerate(pd.read_csv(TEMPLATE_TOXIC2_COMPLETE, chunksize=500000, sep=';',  dtype={'new_template':'category', 'identity': 'category', 'type_identity': 'category','pronoun': 'category', 'pronouns_type': 'category'})), total=20, desc='Creating chunks', unit='chunks'):\n",
    "            chunk.to_csv(TEMPLATE_TOXIC2_CHUNK+'_chunk{}.csv'.format(i), index=False, sep=';')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert a template\n",
    "builder1 = TemplateBuilder(TEMPLATE_TOXIC1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
