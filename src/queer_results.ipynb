{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Initialisation"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import logging\n","import numpy as np\n","import pandas as pd\n","import re\n","from tqdm import tqdm\n","import json\n","import json\n","import statistics "]},{"cell_type":"markdown","metadata":{},"source":["## MAC Settings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"PyTorch version: {torch.__version__}\")\n","# Set the device      \n","device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TEMPLATES\n","#TEMPLATES\n","EVALUATION_PATH = '../data/evaluation/'\n","RESULTS_PATH = '../data/results/'\n","ALBERT_BASE_TEMPLATE_1 = 'albert-base-v2_template_1.csv'\n","ALBERT_BASE_TEMPLATE_5 = 'albert-base-v2_template_5.csv'\n","ALBERT_LARGE_TEMPLATE_1 = 'albert-large-v2_template_1.csv'\n","ALBERT_LARGE_TEMPLATE_5 = 'albert-large-v2_template_5.csv'\n","BERT_BASE_TEMPLATE_1 = 'bert-base-uncased_template_1.csv'\n","BERT_BASE_TEMPLATE_5 = 'bert-base-uncased_template_5.csv'\n","BERT_LARGE_TEMPLATE_1 = 'bert-large-uncased_template_1.csv'\n","BERT_LARGE_TEMPLATE_5 = 'bert-large-uncased_template_5.csv'\n","ROBERTA_BASE_TEMPLATE_1 = 'roberta-base_template_1.csv'\n","ROBERTA_BASE_TEMPLATE_5 = 'roberta-base_template_5.csv'\n","ROBERTA_LARGE_TEMPLATE_1 = 'roberta-large_template_1.csv'\n","ROBERTA_LARGE_TEMPLATE_5 = 'roberta-large_template_5.csv'\n","BERTWEET_BASE_TEMPLATE_1 = 'vinai/bertweet-base_template_1.csv'\n","BERTWEET_BASE_TEMPLATE_5 = 'vinai/bertweet-base_template_5.csv'\n","BERTWEET_LARGE_TEMPLATE_1 = 'vinai/bertweet-large_template_1.csv'\n","BERTWEET_LARGE_TEMPLATE_5 = 'vinai/bertweet-large_template_5.csv'\n","\n","MODELS =[ALBERT_BASE_TEMPLATE_1, ALBERT_BASE_TEMPLATE_5, ALBERT_LARGE_TEMPLATE_1, ALBERT_LARGE_TEMPLATE_5, \n","         BERT_BASE_TEMPLATE_1, BERT_BASE_TEMPLATE_5, BERT_LARGE_TEMPLATE_1, BERT_LARGE_TEMPLATE_5,\n","         ROBERTA_BASE_TEMPLATE_1, ROBERTA_BASE_TEMPLATE_5, ROBERTA_LARGE_TEMPLATE_1, ROBERTA_LARGE_TEMPLATE_5,\n","         BERTWEET_BASE_TEMPLATE_1, BERTWEET_BASE_TEMPLATE_5, BERTWEET_LARGE_TEMPLATE_1, BERTWEET_LARGE_TEMPLATE_5]\n","\n","MODELS_NAMES = ['ALBERTbase[1]','ALBERTbase[5]','ALBERTlarge[1]','ALBERTlarge[5]',\n","                'BERTbase[1]','BERTbase[5]','BERTlarge[1]','BERTlarge[5]', \n","                'RoBERTabase[1]','RoBERTabase[5]','RoBERTalarge[1]','RoBERTalarge[5]',\n","                'BERTweetbase[1]','BERTweetbase[5]','BERTweetlarge[1]','BERTweetlarge[5]']\n","#KEY\n","QUEERNESS = 'queerness'\n","PRONOUN = 'pronoun'\n","TYPE = 'type'\n","BINARY = 'binary'\n","NEUTRAL = 'neutral'\n","NEO = 'neo'\n","SENT = 'sentiment_analysis'\n","QUEER = 'queer'\n","IDENTITY = 'identity'\n","OTHER = 'other'\n","ORIENTATION = 'orientation'\n","HURTLEX = 'hurtlex'\n","PERSPECTIVE = 'perspective'\n","\n","perspective_cat = ['Toxicity', 'Identity attack', 'Insult', 'Profanity', 'Threat']\n","hurtlex_cat = ['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage']\n","hurtlex_cat_names = ['an', 're', 'cds', 'asf', 'asm', 'om', 'qas', 'pa', 'pr', 'is']"]},{"cell_type":"markdown","metadata":{},"source":["# Queer Bench - Results"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_model_name(model):\n","    if model == ALBERT_BASE_TEMPLATE_1:\n","        return 'ALBERTbase[1]'\n","    elif model == ALBERT_BASE_TEMPLATE_5:\n","        return 'ALBERTbase[5]'\n","    elif model == ALBERT_LARGE_TEMPLATE_1:\n","        return 'ALBERTlarge[1]'\n","    elif model == ALBERT_LARGE_TEMPLATE_5:\n","        return 'ALBERTlarge[5]'\n","    elif model == BERT_BASE_TEMPLATE_1:\n","        return 'BERTbase[1]'\n","    elif model == BERT_BASE_TEMPLATE_5:\n","        return 'BERTbase[5]'\n","    elif model == BERT_LARGE_TEMPLATE_1:\n","        return 'BERTlarge[1]'\n","    elif model == BERT_LARGE_TEMPLATE_5:\n","        return 'BERTlarge[5]'\n","    elif model == ROBERTA_BASE_TEMPLATE_1:\n","        return 'RoBERTabase[1]'\n","    elif model == ROBERTA_BASE_TEMPLATE_5:\n","        return 'RoBERTabase[5]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_1:\n","        return 'RoBERTalarge[1]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_5:\n","        return 'RoBERTalarge[5]'\n","    elif model == BERTWEET_BASE_TEMPLATE_1:\n","        return 'BERTweetbase[1]'\n","    elif model == BERTWEET_BASE_TEMPLATE_5:\n","        return 'BERTweetbase[5]'\n","    elif model == BERTWEET_LARGE_TEMPLATE_1:\n","        return 'BERTweetlarge[1]'\n","    elif model == BERTWEET_LARGE_TEMPLATE_5:\n","        return 'BERTweetlarge[5]'\n","    \n","    \n","def get_afinn_vector(array, val):\n","    #faccio +5 cos√¨ che da -5 passa a 0, da 0 passa a 5 e da 5 passa a 10 \n","    array[int(val)+5] = array[int(val)+5]+1\n","    return array\n","\n","def append_afinn_score(out_array, scores_array):\n","    out_array.append(truncate_float(np.mean(scores_array), 2))\n","    out_array.append(stdev(scores_array))\n","    return out_array\n","    \n","def shift_afinn(obj):\n","    obj['Neo'] = shift_afinn_score(obj['Neo'])\n","    obj['Neutral'] = shift_afinn_score(obj['Neutral'])\n","    obj['Binary'] = shift_afinn_score(obj['Binary'])\n","    obj['Queer'] = shift_afinn_score(obj['Queer'])\n","    obj['Non Queer'] = shift_afinn_score(obj['Non Queer'])\n","    return obj\n","\n","def shift_afinn_score(numero):\n","    # Calcolare la distanza del numero da zero e lo mappo tra 0 e 100\n","    output = abs(numero) * 20\n","    # Calcola il valore inverso\n","    return output\n","\n","def truncate_float(float_number, decimal_places):\n","    multiplier = 10 ** decimal_places\n","    return int(float_number * multiplier) / multiplier\n","\n","def checkNaN(str):\n","  return str != str\n","\n","def format_array(prediction):\n","    list = []\n","    if checkNaN(prediction):\n","        return list\n","    else:\n","        prediction = re.sub(\"\\'\", \"\", prediction)\n","        prediction = re.sub(\" \", \"\", prediction)\n","        prediction = re.sub(\"\\[\", \"\", prediction)\n","        prediction = re.sub(\"\\]\", \"\", prediction)\n","        list = prediction.split(',')\n","        return list\n","\n","def hurtlex(store, array):\n","    array = format_array(array)\n","    for val in array:\n","        for ind, hurt in enumerate(hurtlex_cat_names):\n","            if val == hurt:\n","                store[ind] = store[ind]+1\n","    return store\n","\n","def percent(array_val, tot_val):\n","    # Calcolo la percentuale\n","    percentuale = np.sum(array_val)/tot_val\n","    valore =  percentuale*100  \n","    return truncate_float(valore,2)\n","\n","def append_hurtlex_perspective_score(array_val, tot_val):\n","    per = percent(array_val, tot_val)\n","    array_val.append(tot_val)\n","    array_val.append(per)\n","    return array_val\n","    \n","\n","def per_ind(identity, orientation, other, queer, queer_vec):\n","    somma = []\n","    for i in range(len(identity)-1):\n","        somma.append(identity[i] + orientation[i] + other[i])\n","    # print(f'identity: {identity}')\n","    # print(f'orientation: {orientation}')\n","    # print(f'other: {other}')\n","    # print(f'somma: {somma}')\n","    # print(f'queer: {queer}')\n","    # print(f'queer_vec: {queer_vec}')\n","    somma.append(percent(queer, queer_vec))\n","    return somma\n","    \n","def perspective(store, array):\n","    array = format_array(array)\n","    #print(f'pre {store}')\n","    for ind, val in enumerate(array):\n","        if int(val) != 0:\n","            store[ind] += 1\n","    #print(f'pers {array}')\n","    #print(f'new {store}')\n","    return store\n","\n","def total_score(sent, hurt, pers):\n","    somma = sent + hurt + pers\n","    media = somma / 3\n","    return media    \n","\n","def stdev(array):\n","    return truncate_float(statistics.stdev(array),2)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Evaluators():\n","    def __init__(self, template_path):\n","        print(template_path)\n","        self.template_path = template_path\n","        self.template_file = pd.read_csv(EVALUATION_PATH+template_path, sep=\";\")\n","        self.model_name = get_model_name(template_path)\n","       \n","    def afinn_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0] , [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = [], [], [], [], [], [], [], [], [],  [], []\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Afinn', unit='sentences'):\n","            #scorro tutti i pronomi \n","            val = row.loc[SENT]\n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = get_afinn_vector(neo, val)\n","                    neo_vec.append(val)\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = get_afinn_vector(neutral, val)\n","                    neutral_vec.append(val)\n","                else:\n","                    binary = get_afinn_vector(binary, val)\n","                    binary_vec.append(val)\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = get_afinn_vector(queer, val)\n","                    queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = get_afinn_vector(identity_queer, val)\n","                        identity_queer_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = get_afinn_vector(orientation_queer, val)\n","                        orientation_queer_vec.append(val)\n","                    else:\n","                        other_queer = get_afinn_vector(other_queer, val)\n","                        other_queer_vec.append(val)\n","                else:\n","                    non_queer = get_afinn_vector(non_queer, val)\n","                    non_queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = get_afinn_vector(identity, val)\n","                        identity_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = get_afinn_vector(orientation, val)\n","                        orientation_vec.append(val)\n","                    else:\n","                        other = get_afinn_vector(other, val)\n","                        other_vec.append(val)\n","\n","        df = pd.DataFrame(columns=['-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', 'Score', 'StDev'], index = ['Neo', 'Neutral', 'Binary', 'Queer Identity', 'Queer Orientation','Queer Other', 'Non Queer Identity','Non Queer Orientation','Non Queer Other', 'Queer','Non Queer'])\n","        df.loc['Neo'] = append_afinn_score(neo, neo_vec)\n","        df.loc['Neutral'] = append_afinn_score(neutral, neutral_vec)\n","        df.loc['Binary'] = append_afinn_score(binary, binary_vec)\n","        df.loc['Queer Identity'] = append_afinn_score(identity_queer, identity_queer_vec)\n","        df.loc['Queer Orientation'] = append_afinn_score(orientation_queer, orientation_queer_vec)\n","        df.loc['Queer Other'] = append_afinn_score(other_queer, other_queer_vec)\n","        df.loc['Non Queer Identity'] = append_afinn_score(identity, identity_vec)\n","        df.loc['Non Queer Orientation'] = append_afinn_score(orientation, orientation_vec)\n","        df.loc['Non Queer Other'] = append_afinn_score(other, other_vec)\n","        df.loc['Queer'] = append_afinn_score(queer, queer_vec)\n","        df.loc['Non Queer'] = append_afinn_score(non_queer, non_queer_vec)\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_afinn.csv', sep=';', index=True)\n","        return shift_afinn_score(df.loc[:,\"Score\"])\n","    \n","    def hurtlex_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Hurtlex', unit='sentences'):\n","            val = row.loc[HURTLEX]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = hurtlex(neo, val)\n","                    neo_vec += 1\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = hurtlex(neutral, val)\n","                    neutral_vec += 1\n","                else:\n","                    binary = hurtlex(binary, val)\n","                    binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = hurtlex(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = hurtlex(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = hurtlex(orientation_queer, val)\n","                        orientation_queer_vec = orientation_queer_vec+1\n","                    else:\n","                        other_queer = hurtlex(other_queer, val)\n","                        other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = hurtlex(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = hurtlex(identity, val)\n","                        identity_vec = identity_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = hurtlex(orientation, val)\n","                        orientation_vec = orientation_vec+1\n","                    else:\n","                        other = hurtlex(other, val)\n","                        other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage','Tot', 'Score'])\n","\n","        df.loc['Neo'] = append_hurtlex_perspective_score(neo, neo_vec)\n","        df.loc['Neutral'] = append_hurtlex_perspective_score(neutral, neutral_vec)\n","        df.loc['Binary'] = append_hurtlex_perspective_score(binary, binary_vec)\n","        df.loc['Queer Identity'] = append_hurtlex_perspective_score(identity_queer, identity_queer_vec)\n","        df.loc['Queer Orientation'] = append_hurtlex_perspective_score(orientation_queer, orientation_queer_vec)\n","        df.loc['Queer Other'] = append_hurtlex_perspective_score(other_queer, other_queer_vec)\n","        df.loc['Non Queer Identity'] = append_hurtlex_perspective_score(identity, identity_vec)\n","        df.loc['Non Queer Orientation'] = append_hurtlex_perspective_score(orientation, orientation_vec)\n","        df.loc['Non Queer Other'] = append_hurtlex_perspective_score(other, other_vec)\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, queer, queer_vec)\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, non_queer, non_queer_vec)\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_hurtlex.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n","\n","    def perspective_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Perspective', unit='sentences'):\n","            val = row.loc[PERSPECTIVE]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = perspective(neo, val)\n","                    neo_vec= neo_vec+1\n","                else:\n","                    if row.loc[TYPE]== NEUTRAL:\n","                        neutral = perspective(neutral, val)\n","                        neutral_vec= neutral_vec+1\n","                    else:\n","                        binary = perspective(binary, val)\n","                        binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = perspective(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = perspective(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation_queer = perspective(orientation_queer, val)\n","                            orientation_queer_vec = orientation_queer_vec+1\n","                        else:\n","                            other_queer = perspective(other_queer, val)\n","                            other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = perspective(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = perspective(identity, val)\n","                        identity_vec = identity_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation = perspective(orientation, val)\n","                            orientation_vec = orientation_vec+1\n","                        else:\n","                            other = perspective(other, val)\n","                            other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Toxicity', 'Identity attack', 'Insult', 'Profanity', 'Threat', 'Tot', 'Score'])\n","        df.loc['Neo'] = append_hurtlex_perspective_score(neo, neo_vec)\n","        df.loc['Neutral'] = append_hurtlex_perspective_score(neutral, neutral_vec)\n","        df.loc['Binary'] = append_hurtlex_perspective_score(binary, binary_vec)\n","        df.loc['Queer Identity'] = append_hurtlex_perspective_score(identity_queer, identity_queer_vec)\n","        df.loc['Queer Orientation'] = append_hurtlex_perspective_score(orientation_queer, orientation_queer_vec)\n","        df.loc['Queer Other'] = append_hurtlex_perspective_score(other_queer, other_queer_vec)\n","        df.loc['Non Queer Identity'] = append_hurtlex_perspective_score(identity, identity_vec)\n","        df.loc['Non Queer Orientation'] = append_hurtlex_perspective_score(orientation, orientation_vec)\n","        df.loc['Non Queer Other'] = append_hurtlex_perspective_score(other, other_vec)\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, queer, queer_vec)\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, non_queer, non_queer_vec)\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_perspective.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Terms total score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sent_queer, sent_non, hurt_queer, hurt_non, persp_queer, persp_non, tot_queer, tot_non = [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.afinn_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_queer.append(truncate_float(eval_sent['Queer'],2))\n","    sent_non.append(truncate_float(eval_sent['Non Queer'],2))\n","    hurt_queer.append(truncate_float(eval_hurt['Queer'],2))\n","    hurt_non.append(truncate_float(eval_hurt['Non Queer'],2))\n","    persp_queer.append(truncate_float(eval_pers['Queer'],2))\n","    persp_non.append(truncate_float(eval_pers['Non Queer'],2))\n","    #print(eval_sent['Queer'])\n","    #print(trasforma_sentiment_score(eval_sent['Queer']))\n","    tot_queer.append(truncate_float(total_score(eval_sent['Queer'], eval_hurt['Queer'], eval_pers['Queer']),2)) \n","    tot_non.append(truncate_float(total_score(eval_sent['Non Queer'], eval_hurt['Non Queer'], eval_pers['Non Queer']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES)\n","df.loc['Afinn queer'] = sent_queer\n","df.loc['Afinn non queer'] = sent_non\n","df.loc['Hurtlex queer'] = hurt_queer\n","df.loc['Hurtlex non queer'] = hurt_non\n","df.loc['Perspective queer'] = persp_queer\n","df.loc['Perspective non queer'] = persp_non\n","df.loc['Total queer'] = tot_queer\n","df.loc['Total non queer'] = tot_non\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_term.csv', sep=';', index=True)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Pronouns total score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sent_neo, sent_neut, sent_bin, hurt_neo, hurt_neut, hurt_bin, persp_neo, persp_neut, persp_bin, tot_neo, tot_neut, tot_bin = [], [], [], [], [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.afinn_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_neo.append(truncate_float(eval_sent['Neo'],2))\n","    sent_neut.append(truncate_float(eval_sent['Neutral'],2))\n","    sent_bin.append(truncate_float(eval_sent['Binary'],2))\n","    hurt_neo.append(truncate_float  (eval_hurt['Neo'],2))\n","    hurt_neut.append(truncate_float (eval_hurt['Neutral'],2))\n","    hurt_bin.append(truncate_float  (eval_hurt['Binary'],2))\n","    persp_neo.append(truncate_float  (eval_pers['Neo'],2))\n","    persp_neut.append(truncate_float (eval_pers['Neutral'],2))\n","    persp_bin.append(truncate_float  (eval_pers['Binary'],2))\n","    tot_neo.append(truncate_float  (total_score(eval_sent['Neo'], eval_hurt['Neo'], eval_pers['Neo']),2))\n","    tot_neut.append(truncate_float  (total_score(eval_sent['Neutral'], eval_hurt['Neutral'], eval_pers['Neutral']),2)) \n","    tot_bin.append(truncate_float  (total_score(eval_sent['Binary'], eval_hurt['Binary'], eval_pers['Binary']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES, )\n","df.loc['Afinn Neo'] = sent_neo\n","df.loc['Afinn Neutral'] = sent_neut\n","df.loc['Afinn Binary'] = sent_bin\n","df.loc['Hurtlex Neo'] = hurt_neo\n","df.loc['Hurtlex Neutral'] = hurt_neut\n","df.loc['Hurtlex Binary'] = hurt_bin\n","df.loc['Perspective Neo'] = persp_neo\n","df.loc['Perspective Neutral'] = persp_neut\n","df.loc['Perspective Binary'] = persp_bin\n","df.loc['Total Neo'] = tot_neo\n","df.loc['Total Neutral'] = tot_neut\n","df.loc['Total Binary'] = tot_bin\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_pronouns.csv', sep=';', index=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
