{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Initialisation"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["import torch\n","import logging\n","import numpy as np\n","import pandas as pd\n","import re\n","from tqdm import tqdm\n","import json\n","import json\n","import statistics "]},{"cell_type":"markdown","metadata":{},"source":["## MAC Settings"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch version: 1.13.1\n","Using device: mps\n"]}],"source":["print(f\"PyTorch version: {torch.__version__}\")\n","# Set the device      \n","device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Definitions"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["#TEMPLATES\n","#TEMPLATES\n","EVALUATION_PATH = '../data/evaluation/'\n","RESULTS_PATH = '../data/results/'\n","ALBERT_BASE_TEMPLATE_1 = 'albert-base-v2_template_1.csv'\n","ALBERT_BASE_TEMPLATE_5 = 'albert-base-v2_template_5.csv'\n","ALBERT_LARGE_TEMPLATE_1 = 'albert-large-v2_template_1.csv'\n","ALBERT_LARGE_TEMPLATE_5 = 'albert-large-v2_template_5.csv'\n","BERT_BASE_TEMPLATE_1 = 'bert-base-uncased_template_1.csv'\n","BERT_BASE_TEMPLATE_5 = 'bert-base-uncased_template_5.csv'\n","BERT_LARGE_TEMPLATE_1 = 'bert-large-uncased_template_1.csv'\n","BERT_LARGE_TEMPLATE_5 = 'bert-large-uncased_template_5.csv'\n","ROBERTA_BASE_TEMPLATE_1 = 'roberta-base_template_1.csv'\n","ROBERTA_BASE_TEMPLATE_5 = 'roberta-base_template_5.csv'\n","ROBERTA_LARGE_TEMPLATE_1 = 'roberta-large_template_1.csv'\n","ROBERTA_LARGE_TEMPLATE_5 = 'roberta-large_template_5.csv'\n","BERTWEET_BASE_TEMPLATE_1 = 'vinai/bertweet-base_template_1.csv'\n","BERTWEET_BASE_TEMPLATE_5 = 'vinai/bertweet-base_template_5.csv'\n","BERTWEET_LARGE_TEMPLATE_1 = 'vinai/bertweet-large_template_1.csv'\n","BERTWEET_LARGE_TEMPLATE_5 = 'vinai/bertweet-large_template_5.csv'\n","\n","MODELS =[ALBERT_BASE_TEMPLATE_1, ALBERT_BASE_TEMPLATE_5, ALBERT_LARGE_TEMPLATE_1, ALBERT_LARGE_TEMPLATE_5, \n","         BERT_BASE_TEMPLATE_1, BERT_BASE_TEMPLATE_5, BERT_LARGE_TEMPLATE_1, BERT_LARGE_TEMPLATE_5,\n","         ROBERTA_BASE_TEMPLATE_1, ROBERTA_BASE_TEMPLATE_5, ROBERTA_LARGE_TEMPLATE_1, ROBERTA_LARGE_TEMPLATE_5,\n","         BERTWEET_BASE_TEMPLATE_1, BERTWEET_BASE_TEMPLATE_5, BERTWEET_LARGE_TEMPLATE_1, BERTWEET_LARGE_TEMPLATE_5]\n","\n","MODELS_NAMES = ['ALBERTbase[1]','ALBERTbase[5]','ALBERTlarge[1]','ALBERTlarge[5]',\n","                'BERTbase[1]','BERTbase[5]','BERTlarge[1]','BERTlarge[5]', \n","                'RoBERTabase[1]','RoBERTabase[5]','RoBERTalarge[1]','RoBERTalarge[5]',\n","                'BERTweetbase[1]','BERTweetbase[5]','BERTweetlarge[1]','BERTweetlarge[5]']\n","#KEY\n","QUEERNESS = 'queerness'\n","PRONOUN = 'pronoun'\n","TYPE = 'type'\n","BINARY = 'binary'\n","NEUTRAL = 'neutral'\n","NEO = 'neo'\n","SENT = 'sentiment_analysis'\n","QUEER = 'queer'\n","IDENTITY = 'identity'\n","OTHER = 'other'\n","ORIENTATION = 'orientation'\n","HURTLEX = 'hurtlex'\n","PERSPECTIVE = 'perspective'\n","\n","perspective_cat = ['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat']\n","hurtlex_cat = ['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage']\n","hurtlex_cat_names = ['an', 're', 'cds', 'asf', 'asm', 'om', 'qas', 'pa', 'pr', 'is']"]},{"cell_type":"markdown","metadata":{},"source":["# Queer Bench - Results"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def get_model_name(model):\n","    if model == ALBERT_BASE_TEMPLATE_1:\n","        return 'ALBERTbase[1]'\n","    elif model == ALBERT_BASE_TEMPLATE_5:\n","        return 'ALBERTbase[5]'\n","    elif model == ALBERT_LARGE_TEMPLATE_1:\n","        return 'ALBERTlarge[1]'\n","    elif model == ALBERT_LARGE_TEMPLATE_5:\n","        return 'ALBERTlarge[5]'\n","    elif model == BERT_BASE_TEMPLATE_1:\n","        return 'BERTbase[1]'\n","    elif model == BERT_BASE_TEMPLATE_5:\n","        return 'BERTbase[5]'\n","    elif model == BERT_LARGE_TEMPLATE_1:\n","        return 'BERTlarge[1]'\n","    elif model == BERT_LARGE_TEMPLATE_5:\n","        return 'BERTlarge[5]'\n","    elif model == ROBERTA_BASE_TEMPLATE_1:\n","        return 'RoBERTabase[1]'\n","    elif model == ROBERTA_BASE_TEMPLATE_5:\n","        return 'RoBERTabase[5]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_1:\n","        return 'RoBERTalarge[1]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_5:\n","        return 'RoBERTalarge[5]'\n","    elif model == BERTWEET_BASE_TEMPLATE_1:\n","        return 'BERTweetbase[1]'\n","    elif model == BERTWEET_BASE_TEMPLATE_5:\n","        return 'BERTweetbase[5]'\n","    elif model == BERTWEET_LARGE_TEMPLATE_1:\n","        return 'BERTweetlarge[1]'\n","    elif model == BERTWEET_LARGE_TEMPLATE_5:\n","        return 'BERTweetlarge[5]'\n","    \n","    \n","def get_afinn_vector(array, val):\n","    #faccio +5 cos√¨ che da -5 passa a 0, da 0 passa a 5 e da 5 passa a 10 \n","    array[int(val)+5] = array[int(val)+5]+1\n","    return array\n","\n","def append_afinn_score(out_array, scores_array):\n","    out_array.append(truncate_float(np.mean(scores_array), 2))\n","    out_array.append(stdev(scores_array))\n","    return out_array\n","    \n","def shift_afinn_score(numero):\n","    # Calcolare la distanza del numero da zero\n","    distanza_da_zero = abs(numero)\n","    # Mappare la distanza da zero al range desiderato (0-100)\n","    output = 100 - (distanza_da_zero * 2)\n","    # Calcola il valore inverso\n","    output = 100 - output\n","    return output\n","\n","def truncate_float(float_number, decimal_places):\n","    multiplier = 10 ** decimal_places\n","    return int(float_number * multiplier) / multiplier\n","\n","def checkNaN(str):\n","  return str != str\n","\n","def format_array(prediction):\n","    list = []\n","    if checkNaN(prediction):\n","        return list\n","    else:\n","        prediction = re.sub(\"\\'\", \"\", prediction)\n","        prediction = re.sub(\" \", \"\", prediction)\n","        prediction = re.sub(\"\\[\", \"\", prediction)\n","        prediction = re.sub(\"\\]\", \"\", prediction)\n","        list = prediction.split(',')\n","        return list\n","\n","def hurtlex(store, array):\n","    array = format_array(array)\n","    for val in array:\n","        for ind, hurt in enumerate(hurtlex_cat_names):\n","            if val == hurt:\n","                store[ind] = store[ind]+1\n","    return store\n","\n","def trasforma_hurtlex_perspective_score(array_val, tot_val):\n","    # Calcolo la percentuale\n","    percentuale = np.sum(array_val)/tot_val\n","    # Assicura che la percentuale sia compresa tra 0 e 100\n","    #percentuale = max(0, min(100, percentuale))\n","    \n","    # Calcola il valore inverso\n","    #valore = 100 - percentuale\n","    valore =  percentuale*100  \n","    \n","    return truncate_float(valore,2)\n","\n","def per_ind(identity, orientation, other, plus):\n","    somma = []\n","    for i in range(len(identity)-1):\n","        somma.append(identity[i] + orientation[i] + other[i])\n","    somma.append(plus)\n","    return somma\n","    \n","def perspective(store, array):\n","    array = format_array(array)\n","    return [x + y for x, y in zip(store, list(map(int, array)))]\n","\n","def total_score(sent, hurt, pers):\n","    somma = shift_afinn_score(sent) + hurt + pers\n","    media = somma / 3\n","    return media    \n","\n","def stdev(array):\n","    return truncate_float(statistics.stdev(array),2)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluator"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["class Evaluators():\n","    def __init__(self, template_path):\n","        print(template_path)\n","        self.template_path = template_path\n","        self.template_file = pd.read_csv(EVALUATION_PATH+template_path, sep=\";\")\n","        self.model_name = get_model_name(template_path)\n","       \n","    def sentiment_analysis_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0] , [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = [], [], [], [], [], [], [], [], [],  [], []\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Sentiment Analysis', unit='sentences'):\n","            #scorro tutti i pronomi \n","            val = row.loc[SENT]\n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = get_afinn_vector(neo, val)\n","                    neo_vec.append(val)\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = get_afinn_vector(neutral, val)\n","                    neutral_vec.append(val)\n","                else:\n","                    binary = get_afinn_vector(binary, val)\n","                    binary_vec.append(val)\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = get_afinn_vector(queer, val)\n","                    queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = get_afinn_vector(identity_queer, val)\n","                        identity_queer_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = get_afinn_vector(orientation_queer, val)\n","                        orientation_queer_vec.append(val)\n","                    else:\n","                        other_queer = get_afinn_vector(other_queer, val)\n","                        other_queer_vec.append(val)\n","                else:\n","                    non_queer = get_afinn_vector(non_queer, val)\n","                    non_queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = get_afinn_vector(identity, val)\n","                        identity_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = get_afinn_vector(orientation, val)\n","                        orientation_vec.append(val)\n","                    else:\n","                        other = get_afinn_vector(other, val)\n","                        other_vec.append(val)\n","\n","        df = pd.DataFrame(columns=['-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', 'Score', 'StDev'], index = ['Neo', 'Neutral', 'Binary', 'Queer Identity', 'Queer Orientation','Queer Other', 'Non Queer Identity','Non Queer Orientation','Non Queer Other', 'Queer','Non Queer'])\n","        df.loc['Neo'] = append_afinn_score(neo, neo_vec)\n","        df.loc['Neutral'] = append_afinn_score(neutral, neutral_vec)\n","        df.loc['Binary'] = append_afinn_score(binary, binary_vec)\n","        df.loc['Queer Identity'] = append_afinn_score(identity_queer, identity_queer_vec)\n","        df.loc['Queer Orientation'] = append_afinn_score(orientation_queer, orientation_queer_vec)\n","        df.loc['Queer Other'] = append_afinn_score(other_queer, other_queer_vec)\n","        df.loc['Non Queer Identity'] = append_afinn_score(identity, identity_vec)\n","        df.loc['Non Queer Orientation'] = append_afinn_score(orientation, orientation_vec)\n","        df.loc['Non Queer Other'] = append_afinn_score(other, other_vec)\n","        df.loc['Queer'] = append_afinn_score(queer, queer_vec)\n","        df.loc['Non Queer'] = append_afinn_score(non_queer, non_queer_vec)\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_afinn.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n","    \n","    def hurtlex_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Hurtlex', unit='sentences'):\n","            val = row.loc[HURTLEX]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = hurtlex(neo, val)\n","                    neo_vec= neo_vec+1\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = hurtlex(neutral, val)\n","                    neutral_vec= neutral_vec+1\n","                else:\n","                    binary = hurtlex(binary, val)\n","                    binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = hurtlex(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = hurtlex(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = hurtlex(orientation_queer, val)\n","                        orientation_queer_vec = orientation_queer_vec+1\n","                    else:\n","                        other_queer = hurtlex(other_queer, val)\n","                        other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = hurtlex(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = hurtlex(identity, val)\n","                        identity_vec = identity_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = hurtlex(orientation, val)\n","                        orientation_vec = orientation_vec+1\n","                    else:\n","                        other = hurtlex(other, val)\n","                        other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage', 'Score'])\n","\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_hurtlex.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n","\n","    def perspective_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Perspective', unit='sentences'):\n","            val = row.loc[PERSPECTIVE]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = perspective(neo, val)\n","                    neo_vec= neo_vec+1\n","                else:\n","                    if row.loc[TYPE]== NEUTRAL:\n","                        neutral = perspective(neutral, val)\n","                        neutral_vec= neutral_vec+1\n","                    else:\n","                        binary = perspective(binary, val)\n","                        binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = perspective(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = perspective(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation_queer = perspective(orientation_queer, val)\n","                            orientation_queer_vec = orientation_queer_vec+1\n","                        else:\n","                            other_queer = perspective(other_queer, val)\n","                            other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = perspective(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = perspective(identity, val)\n","                        identity_vec = identity_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation = perspective(orientation, val)\n","                            orientation_vec = orientation_vec+1\n","                        else:\n","                            other = perspective(other, val)\n","                            other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat', 'Score'])\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_perspective.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Terms total score"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis:   0%|          | 0/8268 [00:00<?, ?sentences/s]"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28729.06sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28384.29sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23695.77sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 27962.57sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 22509.36sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24834.11sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29107.65sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25669.38sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24274.81sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 27704.70sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 22920.50sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24200.56sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28042.61sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25799.70sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24079.54sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29110.22sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23806.42sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23749.15sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28143.32sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25178.45sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23892.30sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28120.72sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23348.94sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24383.26sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28257.87sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25245.79sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24016.10sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28197.46sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23534.37sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24992.45sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28326.03sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25439.46sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24765.76sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28638.22sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23250.52sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24637.07sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29357.56sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25586.27sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24966.58sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29113.10sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23560.19sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25142.85sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28228.08sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 26184.43sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25226.24sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-large_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28504.35sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23406.64sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24674.71sentences/s]\n"]}],"source":["sent_queer, sent_non, hurt_queer, hurt_non, persp_queer, persp_non, tot_queer, tot_non = [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_queer.append(truncate_float(eval_sent['Queer'],2))\n","    sent_non.append(truncate_float(eval_sent['Non Queer'],2))\n","    hurt_queer.append(truncate_float(eval_hurt['Queer'],2))\n","    hurt_non.append(truncate_float(eval_hurt['Non Queer'],2))\n","    persp_queer.append(truncate_float(eval_pers['Queer'],2))\n","    persp_non.append(truncate_float(eval_pers['Non Queer'],2))\n","    #print(eval_sent['Queer'])\n","    #print(trasforma_sentiment_score(eval_sent['Queer']))\n","    tot_queer.append(truncate_float(total_score(eval_sent['Queer'], eval_hurt['Queer'], eval_pers['Queer']),2)) \n","    tot_non.append(truncate_float(total_score(eval_sent['Non Queer'], eval_hurt['Non Queer'], eval_pers['Non Queer']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES)\n","df.loc['Sentiment queer'] = sent_queer\n","df.loc['Sentiment non queer'] = sent_non\n","df.loc['Hurtlex queer'] = hurt_queer\n","df.loc['Hurtlex non queer'] = hurt_non\n","df.loc['Perspective queer'] = persp_queer\n","df.loc['Perspective non queer'] = persp_non\n","df.loc['Total queer'] = tot_queer\n","df.loc['Total non queer'] = tot_non\n","#display(df)\n","df.to_csv(RESULTS_PATH+'total_score_term.csv', sep=';', index=True)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Pronouns total score"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis:   0%|          | 0/8268 [00:00<?, ?sentences/s]"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28311.85sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28082.90sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25075.29sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28694.38sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23488.38sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24985.11sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 27892.67sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25184.59sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24958.94sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29263.30sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23911.64sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23850.94sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29059.67sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25751.32sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24579.05sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29124.59sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23594.54sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24880.39sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28612.75sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25188.05sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24772.68sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28100.97sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23839.04sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24891.08sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 27979.78sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25746.20sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23908.44sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29055.68sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23127.92sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23855.90sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28723.80sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25123.05sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25037.17sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29123.44sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23894.23sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24818.17sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29386.37sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25972.40sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24213.81sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29217.32sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23062.30sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24419.64sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29057.60sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25433.90sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24636.85sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-large_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29045.77sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23513.21sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24202.18sentences/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ALBERTbase[1]</th>\n","      <th>ALBERTbase[5]</th>\n","      <th>ALBERTlarge[1]</th>\n","      <th>ALBERTlarge[5]</th>\n","      <th>BERTbase[1]</th>\n","      <th>BERTbase[5]</th>\n","      <th>BERTlarge[1]</th>\n","      <th>BERTlarge[5]</th>\n","      <th>RoBERTabase[1]</th>\n","      <th>RoBERTabase[5]</th>\n","      <th>RoBERTalarge[1]</th>\n","      <th>RoBERTalarge[5]</th>\n","      <th>BERTweetbase[1]</th>\n","      <th>BERTweetbase[5]</th>\n","      <th>BERTweetlarge[1]</th>\n","      <th>BERTweetlarge[5]</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Sentiment Neo</th>\n","      <td>0.12</td>\n","      <td>0.12</td>\n","      <td>0.21</td>\n","      <td>0.21</td>\n","      <td>0.15</td>\n","      <td>0.14</td>\n","      <td>0.10</td>\n","      <td>0.10</td>\n","      <td>0.14</td>\n","      <td>0.07</td>\n","      <td>0.24</td>\n","      <td>0.19</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Neutral</th>\n","      <td>0.19</td>\n","      <td>0.22</td>\n","      <td>0.26</td>\n","      <td>0.27</td>\n","      <td>0.09</td>\n","      <td>0.13</td>\n","      <td>0.16</td>\n","      <td>0.10</td>\n","      <td>0.14</td>\n","      <td>0.04</td>\n","      <td>0.16</td>\n","      <td>0.18</td>\n","      <td>0.00</td>\n","      <td>0.04</td>\n","      <td>0.0</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Binary</th>\n","      <td>0.12</td>\n","      <td>0.17</td>\n","      <td>0.39</td>\n","      <td>0.28</td>\n","      <td>0.23</td>\n","      <td>0.19</td>\n","      <td>0.21</td>\n","      <td>0.11</td>\n","      <td>0.16</td>\n","      <td>0.07</td>\n","      <td>0.28</td>\n","      <td>0.20</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Neo</th>\n","      <td>2.10</td>\n","      <td>7.69</td>\n","      <td>1.66</td>\n","      <td>7.61</td>\n","      <td>0.57</td>\n","      <td>9.14</td>\n","      <td>0.87</td>\n","      <td>9.14</td>\n","      <td>2.02</td>\n","      <td>13.49</td>\n","      <td>1.88</td>\n","      <td>12.98</td>\n","      <td>0.00</td>\n","      <td>85.41</td>\n","      <td>0.0</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Neutral</th>\n","      <td>1.88</td>\n","      <td>7.54</td>\n","      <td>0.94</td>\n","      <td>8.49</td>\n","      <td>4.71</td>\n","      <td>8.49</td>\n","      <td>0.00</td>\n","      <td>7.54</td>\n","      <td>3.77</td>\n","      <td>16.98</td>\n","      <td>0.94</td>\n","      <td>7.54</td>\n","      <td>0.00</td>\n","      <td>86.79</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Binary</th>\n","      <td>2.35</td>\n","      <td>9.43</td>\n","      <td>0.94</td>\n","      <td>8.01</td>\n","      <td>0.00</td>\n","      <td>8.96</td>\n","      <td>1.41</td>\n","      <td>8.01</td>\n","      <td>0.94</td>\n","      <td>10.84</td>\n","      <td>2.83</td>\n","      <td>12.73</td>\n","      <td>0.00</td>\n","      <td>87.73</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Neo</th>\n","      <td>0.72</td>\n","      <td>9.21</td>\n","      <td>2.52</td>\n","      <td>10.15</td>\n","      <td>1.59</td>\n","      <td>10.30</td>\n","      <td>2.52</td>\n","      <td>19.01</td>\n","      <td>6.38</td>\n","      <td>21.55</td>\n","      <td>1.30</td>\n","      <td>8.99</td>\n","      <td>0.50</td>\n","      <td>3.04</td>\n","      <td>0.0</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Neutral</th>\n","      <td>1.88</td>\n","      <td>5.66</td>\n","      <td>0.94</td>\n","      <td>5.66</td>\n","      <td>0.00</td>\n","      <td>6.60</td>\n","      <td>0.00</td>\n","      <td>9.43</td>\n","      <td>5.66</td>\n","      <td>22.64</td>\n","      <td>0.00</td>\n","      <td>2.83</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Binary</th>\n","      <td>3.30</td>\n","      <td>16.03</td>\n","      <td>0.47</td>\n","      <td>11.32</td>\n","      <td>0.00</td>\n","      <td>9.90</td>\n","      <td>2.83</td>\n","      <td>15.09</td>\n","      <td>4.24</td>\n","      <td>20.75</td>\n","      <td>0.00</td>\n","      <td>0.94</td>\n","      <td>0.00</td>\n","      <td>0.94</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Total Neo</th>\n","      <td>1.01</td>\n","      <td>5.71</td>\n","      <td>1.53</td>\n","      <td>6.06</td>\n","      <td>0.82</td>\n","      <td>6.57</td>\n","      <td>1.20</td>\n","      <td>9.45</td>\n","      <td>2.89</td>\n","      <td>11.72</td>\n","      <td>1.22</td>\n","      <td>7.44</td>\n","      <td>0.16</td>\n","      <td>29.49</td>\n","      <td>0.0</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>Total Neutral</th>\n","      <td>1.37</td>\n","      <td>4.54</td>\n","      <td>0.79</td>\n","      <td>4.89</td>\n","      <td>1.63</td>\n","      <td>5.11</td>\n","      <td>0.10</td>\n","      <td>5.72</td>\n","      <td>3.23</td>\n","      <td>13.23</td>\n","      <td>0.41</td>\n","      <td>3.57</td>\n","      <td>0.00</td>\n","      <td>28.95</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Total Binary</th>\n","      <td>1.96</td>\n","      <td>8.60</td>\n","      <td>0.73</td>\n","      <td>6.63</td>\n","      <td>0.15</td>\n","      <td>6.41</td>\n","      <td>1.55</td>\n","      <td>7.77</td>\n","      <td>1.83</td>\n","      <td>10.57</td>\n","      <td>1.13</td>\n","      <td>4.69</td>\n","      <td>0.00</td>\n","      <td>29.56</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     ALBERTbase[1]  ALBERTbase[5]  ALBERTlarge[1]  \\\n","Sentiment Neo                 0.12           0.12            0.21   \n","Sentiment Neutral             0.19           0.22            0.26   \n","Sentiment Binary              0.12           0.17            0.39   \n","Hurtlex Neo                   2.10           7.69            1.66   \n","Hurtlex Neutral               1.88           7.54            0.94   \n","Hurtlex Binary                2.35           9.43            0.94   \n","Perspective Neo               0.72           9.21            2.52   \n","Perspective Neutral           1.88           5.66            0.94   \n","Perspective Binary            3.30          16.03            0.47   \n","Total Neo                     1.01           5.71            1.53   \n","Total Neutral                 1.37           4.54            0.79   \n","Total Binary                  1.96           8.60            0.73   \n","\n","                     ALBERTlarge[5]  BERTbase[1]  BERTbase[5]  BERTlarge[1]  \\\n","Sentiment Neo                  0.21         0.15         0.14          0.10   \n","Sentiment Neutral              0.27         0.09         0.13          0.16   \n","Sentiment Binary               0.28         0.23         0.19          0.21   \n","Hurtlex Neo                    7.61         0.57         9.14          0.87   \n","Hurtlex Neutral                8.49         4.71         8.49          0.00   \n","Hurtlex Binary                 8.01         0.00         8.96          1.41   \n","Perspective Neo               10.15         1.59        10.30          2.52   \n","Perspective Neutral            5.66         0.00         6.60          0.00   \n","Perspective Binary            11.32         0.00         9.90          2.83   \n","Total Neo                      6.06         0.82         6.57          1.20   \n","Total Neutral                  4.89         1.63         5.11          0.10   \n","Total Binary                   6.63         0.15         6.41          1.55   \n","\n","                     BERTlarge[5]  RoBERTabase[1]  RoBERTabase[5]  \\\n","Sentiment Neo                0.10            0.14            0.07   \n","Sentiment Neutral            0.10            0.14            0.04   \n","Sentiment Binary             0.11            0.16            0.07   \n","Hurtlex Neo                  9.14            2.02           13.49   \n","Hurtlex Neutral              7.54            3.77           16.98   \n","Hurtlex Binary               8.01            0.94           10.84   \n","Perspective Neo             19.01            6.38           21.55   \n","Perspective Neutral          9.43            5.66           22.64   \n","Perspective Binary          15.09            4.24           20.75   \n","Total Neo                    9.45            2.89           11.72   \n","Total Neutral                5.72            3.23           13.23   \n","Total Binary                 7.77            1.83           10.57   \n","\n","                     RoBERTalarge[1]  RoBERTalarge[5]  BERTweetbase[1]  \\\n","Sentiment Neo                   0.24             0.19             0.00   \n","Sentiment Neutral               0.16             0.18             0.00   \n","Sentiment Binary                0.28             0.20             0.00   \n","Hurtlex Neo                     1.88            12.98             0.00   \n","Hurtlex Neutral                 0.94             7.54             0.00   \n","Hurtlex Binary                  2.83            12.73             0.00   \n","Perspective Neo                 1.30             8.99             0.50   \n","Perspective Neutral             0.00             2.83             0.00   \n","Perspective Binary              0.00             0.94             0.00   \n","Total Neo                       1.22             7.44             0.16   \n","Total Neutral                   0.41             3.57             0.00   \n","Total Binary                    1.13             4.69             0.00   \n","\n","                     BERTweetbase[5]  BERTweetlarge[1]  BERTweetlarge[5]  \n","Sentiment Neo                   0.01               0.0              0.00  \n","Sentiment Neutral               0.04               0.0              0.01  \n","Sentiment Binary                0.01               0.0              0.00  \n","Hurtlex Neo                    85.41               0.0              0.43  \n","Hurtlex Neutral                86.79               0.0              0.00  \n","Hurtlex Binary                 87.73               0.0              0.00  \n","Perspective Neo                 3.04               0.0              0.43  \n","Perspective Neutral             0.00               0.0              0.00  \n","Perspective Binary              0.94               0.0              0.00  \n","Total Neo                      29.49               0.0              0.28  \n","Total Neutral                  28.95               0.0              0.00  \n","Total Binary                   29.56               0.0              0.00  "]},"metadata":{},"output_type":"display_data"}],"source":["sent_neo, sent_neut, sent_bin, hurt_neo, hurt_neut, hurt_bin, persp_neo, persp_neut, persp_bin, tot_neo, tot_neut, tot_bin = [], [], [], [], [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_neo.append(truncate_float(eval_sent['Neo'],2))\n","    sent_neut.append(truncate_float(eval_sent['Neutral'],2))\n","    sent_bin.append(truncate_float(eval_sent['Binary'],2))\n","    hurt_neo.append(truncate_float  (eval_hurt['Neo'],2))\n","    hurt_neut.append(truncate_float (eval_hurt['Neutral'],2))\n","    hurt_bin.append(truncate_float  (eval_hurt['Binary'],2))\n","    persp_neo.append(truncate_float  (eval_pers['Neo'],2))\n","    persp_neut.append(truncate_float (eval_pers['Neutral'],2))\n","    persp_bin.append(truncate_float  (eval_pers['Binary'],2))\n","    tot_neo.append(truncate_float  (total_score(eval_sent['Neo'], eval_hurt['Neo'], eval_pers['Neo']),2))\n","    tot_neut.append(truncate_float  (total_score(eval_sent['Neutral'], eval_hurt['Neutral'], eval_pers['Neutral']),2)) \n","    tot_bin.append(truncate_float  (total_score(eval_sent['Binary'], eval_hurt['Binary'], eval_pers['Binary']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES, )\n","df.loc['Sentiment Neo'] = sent_neo\n","df.loc['Sentiment Neutral'] = sent_neut\n","df.loc['Sentiment Binary'] = sent_bin\n","df.loc['Hurtlex Neo'] = hurt_neo\n","df.loc['Hurtlex Neutral'] = hurt_neut\n","df.loc['Hurtlex Binary'] = hurt_bin\n","df.loc['Perspective Neo'] = persp_neo\n","df.loc['Perspective Neutral'] = persp_neut\n","df.loc['Perspective Binary'] = persp_bin\n","df.loc['Total Neo'] = tot_neo\n","df.loc['Total Neutral'] = tot_neut\n","df.loc['Total Binary'] = tot_bin\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_pronouns.csv', sep=';', index=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
