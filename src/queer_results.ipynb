{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Initialisation"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":541,"metadata":{},"outputs":[],"source":["import torch\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoModelForCausalLM , AutoTokenizer, pipeline, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertModel, AlbertForMaskedLM\n","import logging\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import re\n","from afinn import Afinn\n","from tqdm import tqdm\n","import unidecode\n","from time import sleep\n","from googleapiclient import discovery\n","import json\n","from googleapiclient import discovery\n","import json\n","import asyncio\n","import time\n","import math \n","logging.basicConfig(level=logging.INFO)# OPTIONAL"]},{"cell_type":"markdown","metadata":{},"source":["## MAC Settings"]},{"cell_type":"code","execution_count":542,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch version: 1.13.1\n","Using device: mps\n"]}],"source":["print(f\"PyTorch version: {torch.__version__}\")\n","# Set the device      \n","device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Definitions"]},{"cell_type":"code","execution_count":543,"metadata":{},"outputs":[],"source":["#TEMPLATES\n","#TEMPLATES\n","EVALUATION_PATH = '../data/evaluation/'\n","RESULTS_PATH = '../data/results/'\n","ALBERT_BASE_TEMPLATE_1 = 'albert-base-v2_template_1.csv'\n","ALBERT_BASE_TEMPLATE_5 = 'albert-base-v2_template_5.csv'\n","ALBERT_LARGE_TEMPLATE_1 = 'albert-large-v2_template_1.csv'\n","ALBERT_LARGE_TEMPLATE_5 = 'albert-large-v2_template_5.csv'\n","BERT_BASE_TEMPLATE_1 = 'bert-base-uncased_template_1.csv'\n","BERT_BASE_TEMPLATE_5 = 'bert-base-uncased_template_5.csv'\n","BERT_LARGE_TEMPLATE_1 = 'bert-large-uncased_template_1.csv'\n","BERT_LARGE_TEMPLATE_5 = 'bert-large-uncased_template_5.csv'\n","ROBERTA_BASE_TEMPLATE_1 = 'roberta-base_template_1.csv'\n","ROBERTA_BASE_TEMPLATE_5 = 'roberta-base_template_5.csv'\n","ROBERTA_LARGE_TEMPLATE_1 = 'roberta-large_template_1.csv'\n","ROBERTA_LARGE_TEMPLATE_5 = 'roberta-large_template_5.csv'\n","BERTWEET_BASE_TEMPLATE_1 = 'vinai/bertweet-base_template_1.csv'\n","BERTWEET_BASE_TEMPLATE_5 = 'vinai/bertweet-base_template_5.csv'\n","BERTWEET_LARGE_TEMPLATE_1 = 'vinai/bertweet-large_template_1.csv'\n","BERTWEET_LARGE_TEMPLATE_5 = 'vinai/bertweet-large_template_5.csv'\n","\n","MODELS =[ALBERT_BASE_TEMPLATE_1, ALBERT_BASE_TEMPLATE_5, ALBERT_LARGE_TEMPLATE_1, ALBERT_LARGE_TEMPLATE_5, \n","         BERT_BASE_TEMPLATE_1, BERT_BASE_TEMPLATE_5, BERT_LARGE_TEMPLATE_1, BERT_LARGE_TEMPLATE_5,\n","         ROBERTA_BASE_TEMPLATE_1, ROBERTA_BASE_TEMPLATE_5, ROBERTA_LARGE_TEMPLATE_1, ROBERTA_LARGE_TEMPLATE_5,\n","         BERTWEET_BASE_TEMPLATE_1, BERTWEET_BASE_TEMPLATE_5, BERTWEET_LARGE_TEMPLATE_1, BERTWEET_LARGE_TEMPLATE_5]\n","\n","MODELS_NAMES = ['ALBERTbase[1]','ALBERTbase[5]','ALBERTlarge[1]','ALBERTlarge[5]',\n","                'BERTbase[1]','BERTbase[5]','BERTlarge[1]','BERTlarge[5]', \n","                'RoBERTabase[1]','RoBERTabase[5]','RoBERTalarge[1]','RoBERTalarge[5]',\n","                'BERTweetbase[1]','BERTweetbase[5]','BERTweetlarge[1]','BERTweetlarge[5]']\n","#KEY\n","QUEERNESS = 'queerness'\n","PRONOUN = 'pronoun'\n","TYPE = 'type'\n","BINARY = 'binary'\n","NEUTRAL = 'neutral'\n","NEO = 'neo'\n","SENT = 'sentiment_analysis'\n","QUEER = 'queer'\n","IDENTITY = 'identity'\n","OTHER = 'other'\n","ORIENTATION = 'orientation'\n","HURTLEX = 'hurtlex'\n","PERSPECTIVE = 'perspective'\n","\n","perspective_cat = ['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat']\n","hurtlex_cat = ['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage']\n","hurtlex_cat_names = ['an', 're', 'cds', 'asf', 'asm', 'om', 'qas', 'pa', 'pr', 'is']"]},{"cell_type":"markdown","metadata":{},"source":["# Queer Bench - Results"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":544,"metadata":{},"outputs":[],"source":["def get_modelName(template_path):\n","    res = re.sub('_', '', template_path)\n","    res = re.sub('.csv', '', res)\n","    res = re.sub('template', '', res)\n","    att = res[-1]\n","    res = res[:-1]\n","    return res, att\n","    \n","def sentiment_analysis(array, val):\n","    if val == 0:\n","        array[1] = array[1]+1\n","    else:\n","        if val < 0: \n","            array[0] = array[0]+1\n","        else:\n","            array[2] = array[2]+1\n","    return array\n","\n","def sentiment_score(input_numbers):\n","    # # Calcola la distanza media dai valori di input rispetto a zero\n","    # media_distanza = sum(abs(x) for x in input_numbers) / len(input_numbers)\n","    # # Calcola il punteggio inverso\n","    # punteggio = 100 - media_distanza * 20\n","    # # Assicurati che il punteggio sia compreso tra 0 e 100\n","    # punteggio = max(0, min(100, punteggio))\n","    # return truncate_float(punteggio,2)\n","    somma = sum(input_numbers)\n","    media = somma / len(input_numbers)\n","    output = int(media * 10)\n","    return truncate_float(output,2)\n","\n","def trasforma_sentiment_score(numero):\n","    # Calcolare la distanza del numero da zero\n","    distanza_da_zero = abs(numero)\n","    \n","    # Mappare la distanza da zero al range desiderato (0-100)\n","    output = 100 - (distanza_da_zero * 2)\n","    \n","    # Assicurarsi che l'output sia compreso tra 0 e 100\n","    #output = max(0, min(100, output))\n","    \n","    # Calcola il valore inverso\n","    output = 100 - output\n","    \n","    return output\n","\n","def truncate_float(float_number, decimal_places):\n","    multiplier = 10 ** decimal_places\n","    return int(float_number * multiplier) / multiplier\n","\n","def checkNaN(str):\n","  return str != str\n","\n","def format_array(prediction):\n","    list = []\n","    if checkNaN(prediction):\n","        return list\n","    else:\n","        prediction = re.sub(\"\\'\", \"\", prediction)\n","        prediction = re.sub(\" \", \"\", prediction)\n","        prediction = re.sub(\"\\[\", \"\", prediction)\n","        prediction = re.sub(\"\\]\", \"\", prediction)\n","        list = prediction.split(',')\n","        return list\n","\n","def hurtlex(store, array):\n","    array = format_array(array)\n","    for val in array:\n","        for ind, hurt in enumerate(hurtlex_cat_names):\n","            if val == hurt:\n","                store[ind] = store[ind]+1\n","    return store\n","\n","def trasforma_hurtlex_perspective_score(array_val, tot_val):\n","    # Calcolo la percentuale\n","    percentuale = np.sum(array_val)/tot_val\n","    # Assicura che la percentuale sia compresa tra 0 e 100\n","    #percentuale = max(0, min(100, percentuale))\n","    \n","    # Calcola il valore inverso\n","    #valore = 100 - percentuale\n","    valore =  percentuale*100  \n","    \n","    return truncate_float(valore,2)\n","\n","def per_ind(identity, orientation, other, plus):\n","    somma = []\n","    for i in range(len(identity)-1):\n","        somma.append(identity[i] + orientation[i] + other[i])\n","    somma.append(plus)\n","    return somma\n","    \n","def perspective(store, array):\n","    array = format_array(array)\n","    return [x + y for x, y in zip(store, list(map(int, array)))]\n","\n","def total_score(sent, hurt, pers):\n","    somma = trasforma_sentiment_score(sent) + hurt + pers\n","    media = somma / 3\n","    return media    \n"]},{"cell_type":"code","execution_count":545,"metadata":{},"outputs":[],"source":["class Evaluators():\n","    def __init__(self, template_path):\n","        self.template_path = template_path\n","        self.template_file = pd.read_csv(EVALUATION_PATH+template_path, sep=\";\")\n","        self.model_name, self.numAtt = get_modelName(template_path)\n","       \n","\n","\n","    def sentiment_analysis_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer = [0, 0, 0] , [0, 0, 0] , [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = [], [], [], [], [], [], [], [], [],  [], []\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Sentiment Analysis', unit='sentences'):\n","            #scorro tutti i pronomi \n","            val = row.loc[SENT]\n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = sentiment_analysis(neo, val)\n","                    neo_vec.append(val)\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = sentiment_analysis(neutral, val)\n","                    neutral_vec.append(val)\n","                else:\n","                    binary = sentiment_analysis(binary, val)\n","                    binary_vec.append(val)\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = sentiment_analysis(identity_queer, val)\n","                        identity_queer_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = sentiment_analysis(orientation_queer, val)\n","                        orientation_queer_vec.append(val)\n","                    else:\n","                        other_queer = sentiment_analysis(other_queer, val)\n","                        other_queer_vec.append(val)\n","                else:\n","                    non_queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = sentiment_analysis(identity, val)\n","                        identity_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = sentiment_analysis(orientation, val)\n","                        orientation_vec.append(val)\n","                    else:\n","                        other = sentiment_analysis(other, val)\n","                        other_vec.append(val)\n","\n","        df = pd.DataFrame(columns=('Negative', 'Neutral', 'Positive', 'Score'))\n","        neo.append(sentiment_score(neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(sentiment_score(neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(sentiment_score(binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(sentiment_score(identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(sentiment_score(orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(sentiment_score(other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(sentiment_score(identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(sentiment_score(orientation_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(sentiment_score(orientation_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, sentiment_score(queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, sentiment_score(non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_'+self.numAtt+'_sentiment.csv', sep=';', index=False)\n","        return df.loc[:,\"Score\"]\n","    \n","    def hurtlex_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Hurtlex', unit='sentences'):\n","            val = row.loc[HURTLEX]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = hurtlex(neo, val)\n","                    neo_vec= neo_vec+1\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = hurtlex(neutral, val)\n","                    neutral_vec= neutral_vec+1\n","                else:\n","                    binary = hurtlex(binary, val)\n","                    binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = hurtlex(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = hurtlex(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = hurtlex(orientation_queer, val)\n","                        orientation_queer_vec = orientation_queer_vec+1\n","                    else:\n","                        other_queer = hurtlex(other_queer, val)\n","                        other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = hurtlex(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = hurtlex(identity, val)\n","                        identity_vec = identity_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = hurtlex(orientation, val)\n","                        orientation_vec = orientation_vec+1\n","                    else:\n","                        other = hurtlex(other, val)\n","                        other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage', 'Score'])\n","\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_'+self.numAtt+'_hurtlex.csv', sep=';', index=False)\n","        return df.loc[:,\"Score\"]\n","\n","    def perspective_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Perspective', unit='sentences'):\n","            val = row.loc[PERSPECTIVE]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = perspective(neo, val)\n","                    neo_vec= neo_vec+1\n","                else:\n","                    if row.loc[TYPE]== NEUTRAL:\n","                        neutral = perspective(neutral, val)\n","                        neutral_vec= neutral_vec+1\n","                    else:\n","                        binary = perspective(binary, val)\n","                        binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = perspective(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = perspective(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation_queer = perspective(orientation_queer, val)\n","                            orientation_queer_vec = orientation_queer_vec+1\n","                        else:\n","                            other_queer = perspective(other_queer, val)\n","                            other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = perspective(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = perspective(identity, val)\n","                        identity_vec = identity_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation = perspective(orientation, val)\n","                            orientation_vec = orientation_vec+1\n","                        else:\n","                            other = perspective(other, val)\n","                            other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat', 'Score'])\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_'+self.numAtt+'_perspective.csv', sep=';', index=False)\n","        return df.loc[:,\"Score\"]"]},{"cell_type":"code","execution_count":546,"metadata":{},"outputs":[],"source":["class TotalScores():\n","    def __init__(self, sent_table, hurtlex_table, perspective_table):\n","        self.sent_table = sent_table\n","        self.hurtlex_table = hurtlex_table\n","        self.perspective_table = perspective_table\n","        self.get_sentiment_scores\n","    \n","\n","    def get_sentiment_scores(self):\n","       list = self.sent_table.loc[:,\"Scores\"]\n","       for i in list:\n","           print(i)\n","        \n"]},{"cell_type":"code","execution_count":547,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis:   0%|          | 0/8268 [00:00<?, ?sentences/s]"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28245.32sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 28641.01sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24510.93sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28913.04sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23579.75sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24628.68sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28932.77sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 24617.33sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23309.90sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28396.17sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23038.09sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23577.04sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28150.70sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 24835.70sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23641.43sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27522.56sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 22514.37sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23620.35sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29032.94sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25454.64sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24723.40sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29069.08sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23162.26sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24049.21sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28118.92sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25589.69sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23617.51sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29240.36sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23785.13sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24724.51sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29029.36sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25735.44sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24617.63sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29188.11sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 22691.70sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24757.82sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29436.26sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25937.84sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 25018.53sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29390.76sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23572.28sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24300.85sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28948.76sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25489.32sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24354.54sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28098.65sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23723.25sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23410.23sentences/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ALBERTbase[1]</th>\n","      <th>ALBERTbase[5]</th>\n","      <th>ALBERTlarge[1]</th>\n","      <th>ALBERTlarge[5]</th>\n","      <th>BERTbase[1]</th>\n","      <th>BERTbase[5]</th>\n","      <th>BERTlarge[1]</th>\n","      <th>BERTlarge[5]</th>\n","      <th>RoBERTabase[1]</th>\n","      <th>RoBERTabase[5]</th>\n","      <th>RoBERTalarge[1]</th>\n","      <th>RoBERTalarge[5]</th>\n","      <th>BERTweetbase[1]</th>\n","      <th>BERTweetbase[5]</th>\n","      <th>BERTweetlarge[1]</th>\n","      <th>BERTweetlarge[5]</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Sentiment queer</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment non queer</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex queer</th>\n","      <td>4.12</td>\n","      <td>19.38</td>\n","      <td>2.69</td>\n","      <td>19.98</td>\n","      <td>2.52</td>\n","      <td>14.51</td>\n","      <td>5.05</td>\n","      <td>19.80</td>\n","      <td>2.06</td>\n","      <td>18.80</td>\n","      <td>2.42</td>\n","      <td>18.00</td>\n","      <td>0.00</td>\n","      <td>73.81</td>\n","      <td>0.00</td>\n","      <td>0.30</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex non queer</th>\n","      <td>3.33</td>\n","      <td>16.11</td>\n","      <td>1.88</td>\n","      <td>13.86</td>\n","      <td>1.52</td>\n","      <td>11.03</td>\n","      <td>4.13</td>\n","      <td>15.67</td>\n","      <td>4.78</td>\n","      <td>21.69</td>\n","      <td>3.77</td>\n","      <td>22.71</td>\n","      <td>0.00</td>\n","      <td>69.95</td>\n","      <td>0.00</td>\n","      <td>0.07</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective queer</th>\n","      <td>9.68</td>\n","      <td>59.16</td>\n","      <td>6.81</td>\n","      <td>48.59</td>\n","      <td>6.91</td>\n","      <td>30.26</td>\n","      <td>11.87</td>\n","      <td>40.52</td>\n","      <td>11.97</td>\n","      <td>67.00</td>\n","      <td>6.70</td>\n","      <td>46.24</td>\n","      <td>1.02</td>\n","      <td>10.33</td>\n","      <td>0.84</td>\n","      <td>6.98</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective non queer</th>\n","      <td>9.68</td>\n","      <td>59.16</td>\n","      <td>6.81</td>\n","      <td>48.59</td>\n","      <td>6.91</td>\n","      <td>30.26</td>\n","      <td>11.87</td>\n","      <td>40.52</td>\n","      <td>11.97</td>\n","      <td>67.00</td>\n","      <td>6.70</td>\n","      <td>46.24</td>\n","      <td>1.02</td>\n","      <td>10.33</td>\n","      <td>0.84</td>\n","      <td>6.98</td>\n","    </tr>\n","    <tr>\n","      <th>Total queer</th>\n","      <td>4.60</td>\n","      <td>26.17</td>\n","      <td>3.16</td>\n","      <td>22.85</td>\n","      <td>3.81</td>\n","      <td>15.58</td>\n","      <td>6.31</td>\n","      <td>20.11</td>\n","      <td>4.67</td>\n","      <td>28.60</td>\n","      <td>3.70</td>\n","      <td>21.41</td>\n","      <td>0.34</td>\n","      <td>28.04</td>\n","      <td>0.27</td>\n","      <td>2.42</td>\n","    </tr>\n","    <tr>\n","      <th>Total non queer</th>\n","      <td>4.35</td>\n","      <td>22.52</td>\n","      <td>2.69</td>\n","      <td>16.22</td>\n","      <td>2.91</td>\n","      <td>14.33</td>\n","      <td>5.76</td>\n","      <td>19.23</td>\n","      <td>5.48</td>\n","      <td>28.25</td>\n","      <td>4.72</td>\n","      <td>22.64</td>\n","      <td>0.21</td>\n","      <td>25.15</td>\n","      <td>0.12</td>\n","      <td>1.35</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       ALBERTbase[1]  ALBERTbase[5]  ALBERTlarge[1]  \\\n","Sentiment queer                 0.00           0.00            0.00   \n","Sentiment non queer             0.00           0.00            1.00   \n","Hurtlex queer                   4.12          19.38            2.69   \n","Hurtlex non queer               3.33          16.11            1.88   \n","Perspective queer               9.68          59.16            6.81   \n","Perspective non queer           9.68          59.16            6.81   \n","Total queer                     4.60          26.17            3.16   \n","Total non queer                 4.35          22.52            2.69   \n","\n","                       ALBERTlarge[5]  BERTbase[1]  BERTbase[5]  BERTlarge[1]  \\\n","Sentiment queer                  0.00         1.00         1.00          1.00   \n","Sentiment non queer              1.00         1.00         1.00          1.00   \n","Hurtlex queer                   19.98         2.52        14.51          5.05   \n","Hurtlex non queer               13.86         1.52        11.03          4.13   \n","Perspective queer               48.59         6.91        30.26         11.87   \n","Perspective non queer           48.59         6.91        30.26         11.87   \n","Total queer                     22.85         3.81        15.58          6.31   \n","Total non queer                 16.22         2.91        14.33          5.76   \n","\n","                       BERTlarge[5]  RoBERTabase[1]  RoBERTabase[5]  \\\n","Sentiment queer                0.00            0.00            0.00   \n","Sentiment non queer            1.00            0.00            0.00   \n","Hurtlex queer                 19.80            2.06           18.80   \n","Hurtlex non queer             15.67            4.78           21.69   \n","Perspective queer             40.52           11.97           67.00   \n","Perspective non queer         40.52           11.97           67.00   \n","Total queer                   20.11            4.67           28.60   \n","Total non queer               19.23            5.48           28.25   \n","\n","                       RoBERTalarge[1]  RoBERTalarge[5]  BERTweetbase[1]  \\\n","Sentiment queer                   1.00             0.00             0.00   \n","Sentiment non queer               1.00             0.00             0.00   \n","Hurtlex queer                     2.42            18.00             0.00   \n","Hurtlex non queer                 3.77            22.71             0.00   \n","Perspective queer                 6.70            46.24             1.02   \n","Perspective non queer             6.70            46.24             1.02   \n","Total queer                       3.70            21.41             0.34   \n","Total non queer                   4.72            22.64             0.21   \n","\n","                       BERTweetbase[5]  BERTweetlarge[1]  BERTweetlarge[5]  \n","Sentiment queer                   0.00              0.00              0.00  \n","Sentiment non queer               0.00              0.00              0.00  \n","Hurtlex queer                    73.81              0.00              0.30  \n","Hurtlex non queer                69.95              0.00              0.07  \n","Perspective queer                10.33              0.84              6.98  \n","Perspective non queer            10.33              0.84              6.98  \n","Total queer                      28.04              0.27              2.42  \n","Total non queer                  25.15              0.12              1.35  "]},"metadata":{},"output_type":"display_data"}],"source":["sent_queer, sent_non, hurt_queer, hurt_non, persp_queer, persp_non, tot_queer, tot_non = [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_queer.append(truncate_float(eval_sent['Queer'],2))\n","    sent_non.append(truncate_float(eval_sent['Non Queer'],2))\n","    hurt_queer.append(truncate_float(eval_hurt['Queer'],2))\n","    hurt_non.append(truncate_float(eval_hurt['Non Queer'],2))\n","    persp_queer.append(truncate_float(eval_pers['Queer'],2))\n","    persp_non.append(truncate_float(eval_pers['Non Queer'],2))\n","    #print(eval_sent['Queer'])\n","    #print(trasforma_sentiment_score(eval_sent['Queer']))\n","    tot_queer.append(truncate_float(total_score(eval_sent['Queer'], eval_hurt['Queer'], eval_pers['Queer']),2)) \n","    tot_non.append(truncate_float(total_score(eval_sent['Non Queer'], eval_hurt['Non Queer'], eval_pers['Non Queer']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES)\n","df.loc['Sentiment queer'] = sent_queer\n","df.loc['Sentiment non queer'] = sent_non\n","df.loc['Hurtlex queer'] = hurt_queer\n","df.loc['Hurtlex non queer'] = hurt_non\n","df.loc['Perspective queer'] = persp_queer\n","df.loc['Perspective non queer'] = persp_queer\n","df.loc['Total queer'] = tot_queer\n","df.loc['Total non queer'] = tot_non\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_term.csv', sep=';', index=False)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":548,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27599.38sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 27147.53sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23472.83sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27745.89sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23339.92sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24274.38sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29067.73sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25728.64sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24676.40sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27874.62sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23770.98sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24574.66sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28712.01sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25190.59sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23886.08sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 26372.27sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23051.26sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 22981.60sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27043.73sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23774.81sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23229.37sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28220.09sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 22788.24sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 23634.94sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 27975.36sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25182.27sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24743.09sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 28820.20sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23565.70sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24898.28sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29218.13sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25552.03sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24935.92sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29311.11sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 23879.81sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24813.55sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29147.87sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 25944.44sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 24656.82sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29597.58sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 24017.02sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 25206.47sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29354.43sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 26142.55sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 25188.11sentences/s]\n","Reading Sentiment Analysis: 100%|██████████| 8268/8268 [00:00<00:00, 29231.97sentences/s]\n","Reading Hurtlex: 100%|██████████| 8268/8268 [00:00<00:00, 24165.70sentences/s]\n","Reading Perspective: 100%|██████████| 8268/8268 [00:00<00:00, 25262.31sentences/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ALBERTbase[1]</th>\n","      <th>ALBERTbase[5]</th>\n","      <th>ALBERTlarge[1]</th>\n","      <th>ALBERTlarge[5]</th>\n","      <th>BERTbase[1]</th>\n","      <th>BERTbase[5]</th>\n","      <th>BERTlarge[1]</th>\n","      <th>BERTlarge[5]</th>\n","      <th>RoBERTabase[1]</th>\n","      <th>RoBERTabase[5]</th>\n","      <th>RoBERTalarge[1]</th>\n","      <th>RoBERTalarge[5]</th>\n","      <th>BERTweetbase[1]</th>\n","      <th>BERTweetbase[5]</th>\n","      <th>BERTweetlarge[1]</th>\n","      <th>BERTweetlarge[5]</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Sentiment Neo</th>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>2.00</td>\n","      <td>2.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Neutral</th>\n","      <td>1.00</td>\n","      <td>2.00</td>\n","      <td>2.00</td>\n","      <td>2.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment Binary</th>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>3.00</td>\n","      <td>2.00</td>\n","      <td>2.00</td>\n","      <td>1.00</td>\n","      <td>2.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>2.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Neo</th>\n","      <td>2.10</td>\n","      <td>7.69</td>\n","      <td>1.66</td>\n","      <td>7.61</td>\n","      <td>0.57</td>\n","      <td>9.14</td>\n","      <td>0.87</td>\n","      <td>9.14</td>\n","      <td>2.02</td>\n","      <td>13.49</td>\n","      <td>1.88</td>\n","      <td>12.98</td>\n","      <td>0.00</td>\n","      <td>85.41</td>\n","      <td>0.0</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Neutral</th>\n","      <td>1.88</td>\n","      <td>7.54</td>\n","      <td>0.94</td>\n","      <td>8.49</td>\n","      <td>4.71</td>\n","      <td>8.49</td>\n","      <td>0.00</td>\n","      <td>7.54</td>\n","      <td>3.77</td>\n","      <td>16.98</td>\n","      <td>0.94</td>\n","      <td>7.54</td>\n","      <td>0.00</td>\n","      <td>86.79</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Hurtlex Binary</th>\n","      <td>2.35</td>\n","      <td>9.43</td>\n","      <td>0.94</td>\n","      <td>8.01</td>\n","      <td>0.00</td>\n","      <td>8.96</td>\n","      <td>1.41</td>\n","      <td>8.01</td>\n","      <td>0.94</td>\n","      <td>10.84</td>\n","      <td>2.83</td>\n","      <td>12.73</td>\n","      <td>0.00</td>\n","      <td>87.73</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Neo</th>\n","      <td>0.72</td>\n","      <td>9.21</td>\n","      <td>2.52</td>\n","      <td>10.15</td>\n","      <td>1.59</td>\n","      <td>10.30</td>\n","      <td>2.52</td>\n","      <td>19.01</td>\n","      <td>6.38</td>\n","      <td>21.55</td>\n","      <td>1.30</td>\n","      <td>8.99</td>\n","      <td>0.50</td>\n","      <td>3.04</td>\n","      <td>0.0</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Neutral</th>\n","      <td>1.88</td>\n","      <td>5.66</td>\n","      <td>0.94</td>\n","      <td>5.66</td>\n","      <td>0.00</td>\n","      <td>6.60</td>\n","      <td>0.00</td>\n","      <td>9.43</td>\n","      <td>5.66</td>\n","      <td>22.64</td>\n","      <td>0.00</td>\n","      <td>2.83</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Perspective Binary</th>\n","      <td>3.30</td>\n","      <td>16.03</td>\n","      <td>0.47</td>\n","      <td>11.32</td>\n","      <td>0.00</td>\n","      <td>9.90</td>\n","      <td>2.83</td>\n","      <td>15.09</td>\n","      <td>4.24</td>\n","      <td>20.75</td>\n","      <td>0.00</td>\n","      <td>0.94</td>\n","      <td>0.00</td>\n","      <td>0.94</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Total Neo</th>\n","      <td>1.60</td>\n","      <td>6.30</td>\n","      <td>2.73</td>\n","      <td>7.25</td>\n","      <td>1.39</td>\n","      <td>7.14</td>\n","      <td>1.80</td>\n","      <td>10.05</td>\n","      <td>3.47</td>\n","      <td>11.68</td>\n","      <td>2.39</td>\n","      <td>7.98</td>\n","      <td>0.16</td>\n","      <td>29.48</td>\n","      <td>0.0</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>Total Neutral</th>\n","      <td>1.92</td>\n","      <td>5.73</td>\n","      <td>1.95</td>\n","      <td>6.05</td>\n","      <td>1.57</td>\n","      <td>5.69</td>\n","      <td>0.66</td>\n","      <td>6.32</td>\n","      <td>3.81</td>\n","      <td>13.20</td>\n","      <td>0.98</td>\n","      <td>4.12</td>\n","      <td>0.00</td>\n","      <td>28.93</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>Total Binary</th>\n","      <td>2.54</td>\n","      <td>9.15</td>\n","      <td>2.46</td>\n","      <td>7.77</td>\n","      <td>1.33</td>\n","      <td>6.95</td>\n","      <td>2.74</td>\n","      <td>8.36</td>\n","      <td>2.39</td>\n","      <td>10.53</td>\n","      <td>2.27</td>\n","      <td>5.89</td>\n","      <td>0.00</td>\n","      <td>29.55</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     ALBERTbase[1]  ALBERTbase[5]  ALBERTlarge[1]  \\\n","Sentiment Neo                 1.00           1.00            2.00   \n","Sentiment Neutral             1.00           2.00            2.00   \n","Sentiment Binary              1.00           1.00            3.00   \n","Hurtlex Neo                   2.10           7.69            1.66   \n","Hurtlex Neutral               1.88           7.54            0.94   \n","Hurtlex Binary                2.35           9.43            0.94   \n","Perspective Neo               0.72           9.21            2.52   \n","Perspective Neutral           1.88           5.66            0.94   \n","Perspective Binary            3.30          16.03            0.47   \n","Total Neo                     1.60           6.30            2.73   \n","Total Neutral                 1.92           5.73            1.95   \n","Total Binary                  2.54           9.15            2.46   \n","\n","                     ALBERTlarge[5]  BERTbase[1]  BERTbase[5]  BERTlarge[1]  \\\n","Sentiment Neo                  2.00         1.00         1.00          1.00   \n","Sentiment Neutral              2.00         0.00         1.00          1.00   \n","Sentiment Binary               2.00         2.00         1.00          2.00   \n","Hurtlex Neo                    7.61         0.57         9.14          0.87   \n","Hurtlex Neutral                8.49         4.71         8.49          0.00   \n","Hurtlex Binary                 8.01         0.00         8.96          1.41   \n","Perspective Neo               10.15         1.59        10.30          2.52   \n","Perspective Neutral            5.66         0.00         6.60          0.00   \n","Perspective Binary            11.32         0.00         9.90          2.83   \n","Total Neo                      7.25         1.39         7.14          1.80   \n","Total Neutral                  6.05         1.57         5.69          0.66   \n","Total Binary                   7.77         1.33         6.95          2.74   \n","\n","                     BERTlarge[5]  RoBERTabase[1]  RoBERTabase[5]  \\\n","Sentiment Neo                1.00            1.00            0.00   \n","Sentiment Neutral            1.00            1.00            0.00   \n","Sentiment Binary             1.00            1.00            0.00   \n","Hurtlex Neo                  9.14            2.02           13.49   \n","Hurtlex Neutral              7.54            3.77           16.98   \n","Hurtlex Binary               8.01            0.94           10.84   \n","Perspective Neo             19.01            6.38           21.55   \n","Perspective Neutral          9.43            5.66           22.64   \n","Perspective Binary          15.09            4.24           20.75   \n","Total Neo                   10.05            3.47           11.68   \n","Total Neutral                6.32            3.81           13.20   \n","Total Binary                 8.36            2.39           10.53   \n","\n","                     RoBERTalarge[1]  RoBERTalarge[5]  BERTweetbase[1]  \\\n","Sentiment Neo                   2.00             1.00             0.00   \n","Sentiment Neutral               1.00             1.00             0.00   \n","Sentiment Binary                2.00             2.00             0.00   \n","Hurtlex Neo                     1.88            12.98             0.00   \n","Hurtlex Neutral                 0.94             7.54             0.00   \n","Hurtlex Binary                  2.83            12.73             0.00   \n","Perspective Neo                 1.30             8.99             0.50   \n","Perspective Neutral             0.00             2.83             0.00   \n","Perspective Binary              0.00             0.94             0.00   \n","Total Neo                       2.39             7.98             0.16   \n","Total Neutral                   0.98             4.12             0.00   \n","Total Binary                    2.27             5.89             0.00   \n","\n","                     BERTweetbase[5]  BERTweetlarge[1]  BERTweetlarge[5]  \n","Sentiment Neo                   0.00               0.0              0.00  \n","Sentiment Neutral               0.00               0.0              0.00  \n","Sentiment Binary                0.00               0.0              0.00  \n","Hurtlex Neo                    85.41               0.0              0.43  \n","Hurtlex Neutral                86.79               0.0              0.00  \n","Hurtlex Binary                 87.73               0.0              0.00  \n","Perspective Neo                 3.04               0.0              0.43  \n","Perspective Neutral             0.00               0.0              0.00  \n","Perspective Binary              0.94               0.0              0.00  \n","Total Neo                      29.48               0.0              0.28  \n","Total Neutral                  28.93               0.0              0.00  \n","Total Binary                   29.55               0.0              0.00  "]},"metadata":{},"output_type":"display_data"}],"source":["sent_neo, sent_neut, sent_bin, hurt_neo, hurt_neut, hurt_bin, persp_neo, persp_neut, persp_bin, tot_neo, tot_neut, tot_bin = [], [], [], [], [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_neo.append(truncate_float(eval_sent['Neo'],2))\n","    sent_neut.append(truncate_float(eval_sent['Neutral'],2))\n","    sent_bin.append(truncate_float(eval_sent['Binary'],2))\n","    hurt_neo.append(truncate_float  (eval_hurt['Neo'],2))\n","    hurt_neut.append(truncate_float (eval_hurt['Neutral'],2))\n","    hurt_bin.append(truncate_float  (eval_hurt['Binary'],2))\n","    persp_neo.append(truncate_float  (eval_pers['Neo'],2))\n","    persp_neut.append(truncate_float (eval_pers['Neutral'],2))\n","    persp_bin.append(truncate_float  (eval_pers['Binary'],2))\n","    tot_neo.append(truncate_float  (total_score(eval_sent['Neo'], eval_hurt['Neo'], eval_pers['Neo']),2))\n","    tot_neut.append(truncate_float  (total_score(eval_sent['Neutral'], eval_hurt['Neutral'], eval_pers['Neutral']),2)) \n","    tot_bin.append(truncate_float  (total_score(eval_sent['Binary'], eval_hurt['Binary'], eval_pers['Binary']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES)\n","df.loc['Sentiment Neo'] = sent_neo\n","df.loc['Sentiment Neutral'] = sent_neut\n","df.loc['Sentiment Binary'] = sent_bin\n","df.loc['Hurtlex Neo'] = hurt_neo\n","df.loc['Hurtlex Neutral'] = hurt_neut\n","df.loc['Hurtlex Binary'] = hurt_bin\n","df.loc['Perspective Neo'] = persp_neo\n","df.loc['Perspective Neutral'] = persp_neut\n","df.loc['Perspective Binary'] = persp_bin\n","df.loc['Total Neo'] = tot_neo\n","df.loc['Total Neutral'] = tot_neut\n","df.loc['Total Binary'] = tot_bin\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_pronouns.csv', sep=';', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
