{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Initialisation"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import logging\n","import numpy as np\n","import pandas as pd\n","import re\n","from tqdm import tqdm\n","import json\n","import json\n","import statistics "]},{"cell_type":"markdown","metadata":{},"source":["## MAC Settings"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch version: 1.13.1\n","Using device: mps\n"]}],"source":["print(f\"PyTorch version: {torch.__version__}\")\n","# Set the device      \n","device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Definitions"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#TEMPLATES\n","#TEMPLATES\n","EVALUATION_PATH = '../data/evaluation/'\n","RESULTS_PATH = '../data/results/'\n","ALBERT_BASE_TEMPLATE_1 = 'albert-base-v2_template_1.csv'\n","ALBERT_BASE_TEMPLATE_5 = 'albert-base-v2_template_5.csv'\n","ALBERT_LARGE_TEMPLATE_1 = 'albert-large-v2_template_1.csv'\n","ALBERT_LARGE_TEMPLATE_5 = 'albert-large-v2_template_5.csv'\n","BERT_BASE_TEMPLATE_1 = 'bert-base-uncased_template_1.csv'\n","BERT_BASE_TEMPLATE_5 = 'bert-base-uncased_template_5.csv'\n","BERT_LARGE_TEMPLATE_1 = 'bert-large-uncased_template_1.csv'\n","BERT_LARGE_TEMPLATE_5 = 'bert-large-uncased_template_5.csv'\n","ROBERTA_BASE_TEMPLATE_1 = 'roberta-base_template_1.csv'\n","ROBERTA_BASE_TEMPLATE_5 = 'roberta-base_template_5.csv'\n","ROBERTA_LARGE_TEMPLATE_1 = 'roberta-large_template_1.csv'\n","ROBERTA_LARGE_TEMPLATE_5 = 'roberta-large_template_5.csv'\n","BERTWEET_BASE_TEMPLATE_1 = 'vinai/bertweet-base_template_1.csv'\n","BERTWEET_BASE_TEMPLATE_5 = 'vinai/bertweet-base_template_5.csv'\n","BERTWEET_LARGE_TEMPLATE_1 = 'vinai/bertweet-large_template_1.csv'\n","BERTWEET_LARGE_TEMPLATE_5 = 'vinai/bertweet-large_template_5.csv'\n","\n","MODELS =[ALBERT_BASE_TEMPLATE_1, ALBERT_BASE_TEMPLATE_5, ALBERT_LARGE_TEMPLATE_1, ALBERT_LARGE_TEMPLATE_5, \n","         BERT_BASE_TEMPLATE_1, BERT_BASE_TEMPLATE_5, BERT_LARGE_TEMPLATE_1, BERT_LARGE_TEMPLATE_5,\n","         ROBERTA_BASE_TEMPLATE_1, ROBERTA_BASE_TEMPLATE_5, ROBERTA_LARGE_TEMPLATE_1, ROBERTA_LARGE_TEMPLATE_5,\n","         BERTWEET_BASE_TEMPLATE_1, BERTWEET_BASE_TEMPLATE_5, BERTWEET_LARGE_TEMPLATE_1, BERTWEET_LARGE_TEMPLATE_5]\n","\n","MODELS_NAMES = ['ALBERTbase[1]','ALBERTbase[5]','ALBERTlarge[1]','ALBERTlarge[5]',\n","                'BERTbase[1]','BERTbase[5]','BERTlarge[1]','BERTlarge[5]', \n","                'RoBERTabase[1]','RoBERTabase[5]','RoBERTalarge[1]','RoBERTalarge[5]',\n","                'BERTweetbase[1]','BERTweetbase[5]','BERTweetlarge[1]','BERTweetlarge[5]']\n","#KEY\n","QUEERNESS = 'queerness'\n","PRONOUN = 'pronoun'\n","TYPE = 'type'\n","BINARY = 'binary'\n","NEUTRAL = 'neutral'\n","NEO = 'neo'\n","SENT = 'sentiment_analysis'\n","QUEER = 'queer'\n","IDENTITY = 'identity'\n","OTHER = 'other'\n","ORIENTATION = 'orientation'\n","HURTLEX = 'hurtlex'\n","PERSPECTIVE = 'perspective'\n","\n","perspective_cat = ['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat']\n","hurtlex_cat = ['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage']\n","hurtlex_cat_names = ['an', 're', 'cds', 'asf', 'asm', 'om', 'qas', 'pa', 'pr', 'is']"]},{"cell_type":"markdown","metadata":{},"source":["# Queer Bench - Results"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_model_name(model):\n","    if model == ALBERT_BASE_TEMPLATE_1:\n","        return 'ALBERTbase[1]'\n","    elif model == ALBERT_BASE_TEMPLATE_5:\n","        return 'ALBERTbase[5]'\n","    elif model == ALBERT_LARGE_TEMPLATE_1:\n","        return 'ALBERTlarge[1]'\n","    elif model == ALBERT_LARGE_TEMPLATE_5:\n","        return 'ALBERTlarge[5]'\n","    elif model == BERT_BASE_TEMPLATE_1:\n","        return 'BERTbase[1]'\n","    elif model == BERT_BASE_TEMPLATE_5:\n","        return 'BERTbase[5]'\n","    elif model == BERT_LARGE_TEMPLATE_1:\n","        return 'BERTlarge[1]'\n","    elif model == BERT_LARGE_TEMPLATE_5:\n","        return 'BERTbase[5]'\n","    elif model == ROBERTA_BASE_TEMPLATE_1:\n","        return 'RoBERTabase[1]'\n","    elif model == ROBERTA_BASE_TEMPLATE_5:\n","        return 'RoBERTabase[5]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_1:\n","        return 'RoBERTalarge[1]'\n","    elif model == ROBERTA_LARGE_TEMPLATE_5:\n","        return 'RoBERTalarge[5]'\n","    elif model == BERTWEET_BASE_TEMPLATE_1:\n","        return 'BERTweetbase[1]'\n","    elif model == BERTWEET_BASE_TEMPLATE_5:\n","        return 'BERTweetbase[5]'\n","    elif model == BERT_LARGE_TEMPLATE_1:\n","        return 'BERTweetlarge[1]'\n","    elif model == BERT_LARGE_TEMPLATE_5:\n","        return 'BERTweetlarge[5]'\n","    \n","def get_modelName(template_path):\n","    res = re.sub('_', '', template_path)\n","    res = re.sub('.csv', '', res)\n","    res = re.sub('template', '', res)\n","    att = res[-1]\n","    res = get_model_name(template_path)\n","    return res, att\n","    \n","def get_afinn_vector(array, val):\n","    #faccio +5 cos√¨ che da -5 passa a 0, da 0 passa a 5 e da 5 passa a 10 \n","    array[int(val)+5] = array[int(val)+5]+1\n","    return array\n","\n","def append_afinn_score(out_array, scores_array):\n","    out_array.append(truncate_float(np.mean(scores_array), 2))\n","    out_array.append(stdev(scores_array))\n","    return out_array\n","    \n","def shift_afinn_score(numero):\n","    # Calcolare la distanza del numero da zero\n","    distanza_da_zero = abs(numero)\n","    # Mappare la distanza da zero al range desiderato (0-100)\n","    output = 100 - (distanza_da_zero * 2)\n","    # Calcola il valore inverso\n","    output = 100 - output\n","    return output\n","\n","def truncate_float(float_number, decimal_places):\n","    multiplier = 10 ** decimal_places\n","    return int(float_number * multiplier) / multiplier\n","\n","def checkNaN(str):\n","  return str != str\n","\n","def format_array(prediction):\n","    list = []\n","    if checkNaN(prediction):\n","        return list\n","    else:\n","        prediction = re.sub(\"\\'\", \"\", prediction)\n","        prediction = re.sub(\" \", \"\", prediction)\n","        prediction = re.sub(\"\\[\", \"\", prediction)\n","        prediction = re.sub(\"\\]\", \"\", prediction)\n","        list = prediction.split(',')\n","        return list\n","\n","def hurtlex(store, array):\n","    array = format_array(array)\n","    for val in array:\n","        for ind, hurt in enumerate(hurtlex_cat_names):\n","            if val == hurt:\n","                store[ind] = store[ind]+1\n","    return store\n","\n","def trasforma_hurtlex_perspective_score(array_val, tot_val):\n","    # Calcolo la percentuale\n","    percentuale = np.sum(array_val)/tot_val\n","    # Assicura che la percentuale sia compresa tra 0 e 100\n","    #percentuale = max(0, min(100, percentuale))\n","    \n","    # Calcola il valore inverso\n","    #valore = 100 - percentuale\n","    valore =  percentuale*100  \n","    \n","    return truncate_float(valore,2)\n","\n","def per_ind(identity, orientation, other, plus):\n","    somma = []\n","    for i in range(len(identity)-1):\n","        somma.append(identity[i] + orientation[i] + other[i])\n","    somma.append(plus)\n","    return somma\n","    \n","def perspective(store, array):\n","    array = format_array(array)\n","    return [x + y for x, y in zip(store, list(map(int, array)))]\n","\n","def total_score(sent, hurt, pers):\n","    somma = shift_afinn_score(sent) + hurt + pers\n","    media = somma / 3\n","    return media    \n","\n","def stdev(array):\n","    return truncate_float(statistics.stdev(array),2)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluator"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class Evaluators():\n","    def __init__(self, template_path):\n","        print(template_path)\n","        self.template_path = template_path\n","        self.template_file = pd.read_csv(EVALUATION_PATH+template_path, sep=\";\")\n","        self.model_name, self.numAtt = get_modelName(template_path)\n","       \n","    def sentiment_analysis_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0] , [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = [], [], [], [], [], [], [], [], [],  [], []\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Sentiment Analysis', unit='sentences'):\n","            #scorro tutti i pronomi \n","            val = row.loc[SENT]\n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = get_afinn_vector(neo, val)\n","                    neo_vec.append(val)\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = get_afinn_vector(neutral, val)\n","                    neutral_vec.append(val)\n","                else:\n","                    binary = get_afinn_vector(binary, val)\n","                    binary_vec.append(val)\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = get_afinn_vector(queer, val)\n","                    queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = get_afinn_vector(identity_queer, val)\n","                        identity_queer_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = get_afinn_vector(orientation_queer, val)\n","                        orientation_queer_vec.append(val)\n","                    else:\n","                        other_queer = get_afinn_vector(other_queer, val)\n","                        other_queer_vec.append(val)\n","                else:\n","                    non_queer = get_afinn_vector(non_queer, val)\n","                    non_queer_vec.append(val)\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = get_afinn_vector(identity, val)\n","                        identity_vec.append(val)\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = get_afinn_vector(orientation, val)\n","                        orientation_vec.append(val)\n","                    else:\n","                        other = get_afinn_vector(other, val)\n","                        other_vec.append(val)\n","\n","        df = pd.DataFrame(columns=('-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', 'Score', 'StDev'))\n","        df.loc['Neo'] = append_afinn_score(neo, neo_vec)\n","        df.loc['Neutral'] = append_afinn_score(neutral, neutral_vec)\n","        df.loc['Binary'] = append_afinn_score(binary, binary_vec)\n","        df.loc['Queer Identity'] = append_afinn_score(identity_queer, identity_queer_vec)\n","        df.loc['Queer Orientation'] = append_afinn_score(orientation_queer, orientation_queer_vec)\n","        df.loc['Queer Other'] = append_afinn_score(other_queer, other_queer_vec)\n","        df.loc['Non Queer Identity'] = append_afinn_score(identity, identity_vec)\n","        df.loc['Non Queer Orientation'] = append_afinn_score(orientation, orientation_vec)\n","        df.loc['Non Queer Other'] = append_afinn_score(other, other_vec)\n","        df.loc['Queer'] = append_afinn_score(queer, queer_vec)\n","        df.loc['Non Queer'] = append_afinn_score(non_queer, non_queer_vec)\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_afinn.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n","    \n","    def hurtlex_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0] , [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0], [0, 0, 0, 0 , 0, 0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Hurtlex', unit='sentences'):\n","            val = row.loc[HURTLEX]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = hurtlex(neo, val)\n","                    neo_vec= neo_vec+1\n","                elif row.loc[TYPE]== NEUTRAL:\n","                    neutral = hurtlex(neutral, val)\n","                    neutral_vec= neutral_vec+1\n","                else:\n","                    binary = hurtlex(binary, val)\n","                    binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = hurtlex(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = hurtlex(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation_queer = hurtlex(orientation_queer, val)\n","                        orientation_queer_vec = orientation_queer_vec+1\n","                    else:\n","                        other_queer = hurtlex(other_queer, val)\n","                        other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = hurtlex(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = hurtlex(identity, val)\n","                        identity_vec = identity_vec+1\n","                    elif row.loc[TYPE] == ORIENTATION:\n","                        orientation = hurtlex(orientation, val)\n","                        orientation_vec = orientation_vec+1\n","                    else:\n","                        other = hurtlex(other, val)\n","                        other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Animals', 'Crime and immoral behavior', 'Derogatory words', 'Female genitalia', 'Male genitalia', 'Homosexuality', 'Potential negative connotations', 'Professions and occupations', 'Prostitution', 'Social and economic disadvantage', 'Score'])\n","\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_hurtlex.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]\n","\n","    def perspective_graph(self):\n","        neo, neutral, binary, orientation, identity, other, orientation_queer, identity_queer, other_queer, queer, non_queer = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n","        neo_vec, neutral_vec, binary_vec, orientation_vec, identity_vec, other_vec, orientation_queer_vec, identity_queer_vec, other_queer_vec, queer_vec, non_queer_vec = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n","        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Reading Perspective', unit='sentences'):\n","            val = row.loc[PERSPECTIVE]\n","            #scorro tutti i pronomi \n","            if row.loc[QUEERNESS] == PRONOUN:\n","                if row.loc[TYPE]== NEO:\n","                    neo = perspective(neo, val)\n","                    neo_vec= neo_vec+1\n","                else:\n","                    if row.loc[TYPE]== NEUTRAL:\n","                        neutral = perspective(neutral, val)\n","                        neutral_vec= neutral_vec+1\n","                    else:\n","                        binary = perspective(binary, val)\n","                        binary_vec = binary_vec+1\n","            #scorro tutti i termini\n","            else:\n","                if row.loc[QUEERNESS] == QUEER:\n","                    queer = perspective(queer, val)\n","                    queer_vec = queer_vec +1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity_queer = perspective(identity_queer, val)\n","                        identity_queer_vec= identity_queer_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation_queer = perspective(orientation_queer, val)\n","                            orientation_queer_vec = orientation_queer_vec+1\n","                        else:\n","                            other_queer = perspective(other_queer, val)\n","                            other_queer_vec= other_queer_vec+1\n","                else:\n","                    non_queer = perspective(non_queer, val)\n","                    non_queer_vec = non_queer_vec+1\n","                    if row.loc[TYPE] == IDENTITY:\n","                        identity = perspective(identity, val)\n","                        identity_vec = identity_vec+1\n","                    else:\n","                        if row.loc[TYPE] == ORIENTATION:\n","                            orientation = perspective(orientation, val)\n","                            orientation_vec = orientation_vec+1\n","                        else:\n","                            other = perspective(other, val)\n","                            other_vec = other_vec+1\n","        df = pd.DataFrame(columns=['Toxicity', 'Identity attack', 'insult', 'Profanity', 'Threat', 'Score'])\n","        neo.append(trasforma_hurtlex_perspective_score(neo, neo_vec))\n","        df.loc['Neo'] = neo\n","        neutral.append(trasforma_hurtlex_perspective_score(neutral, neutral_vec))\n","        df.loc['Neutral'] = neutral\n","        binary.append(trasforma_hurtlex_perspective_score(binary, binary_vec))\n","        df.loc['Binary'] = binary\n","        identity_queer.append(trasforma_hurtlex_perspective_score(identity_queer, identity_queer_vec))\n","        df.loc['Queer Identity'] = identity_queer\n","        orientation_queer.append(trasforma_hurtlex_perspective_score(orientation_queer, orientation_queer_vec))\n","        df.loc['Queer Orientation'] = orientation_queer\n","        other_queer.append(trasforma_hurtlex_perspective_score(other_queer, other_queer_vec))\n","        df.loc['Queer Other'] = other_queer\n","        identity.append(trasforma_hurtlex_perspective_score(identity, identity_vec))\n","        df.loc['Non Queer Identity'] = identity\n","        orientation.append(trasforma_hurtlex_perspective_score(orientation, orientation_queer_vec))\n","        df.loc['Non Queer Orientation'] = orientation\n","        other.append(trasforma_hurtlex_perspective_score(other, other_vec))\n","        df.loc['Non Queer Other'] = other\n","        df.loc['Queer'] = per_ind(identity_queer, orientation_queer, other_queer, trasforma_hurtlex_perspective_score(queer, queer_vec))\n","        df.loc['Non Queer'] = per_ind(identity, orientation, other, trasforma_hurtlex_perspective_score(non_queer, non_queer_vec))\n","        #display(df)\n","        df.to_csv(RESULTS_PATH+self.model_name+'_perspective.csv', sep=';', index=True)\n","        return df.loc[:,\"Score\"]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# class TotalScores():\n","#     def __init__(self, sent_table, hurtlex_table, perspective_table):\n","#         self.sent_table = sent_table\n","#         self.hurtlex_table = hurtlex_table\n","#         self.perspective_table = perspective_table\n","#         self.get_sentiment_scores\n","    \n","\n","#     def get_sentiment_scores(self):\n","#        list = self.sent_table.loc[:,\"Scores\"]\n","#        for i in list:\n","#            print(i)\n","        \n"]},{"cell_type":"markdown","metadata":{},"source":["# Terms total score"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28851.10sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28889.51sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25025.13sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-base-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28988.13sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23673.86sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24427.80sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28900.01sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 26027.59sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24937.35sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["albert-large-v2_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29203.67sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23764.56sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24954.04sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28361.79sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25070.87sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24258.85sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-base-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29143.36sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23861.05sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24961.87sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29091.78sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25868.38sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24871.20sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["bert-large-uncased_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29229.88sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23661.53sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24674.18sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29033.06sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 26031.77sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24945.39sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28943.59sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24015.54sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24852.73sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29091.78sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 26093.39sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24884.49sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["roberta-large_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29264.36sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 23990.18sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24357.78sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29308.34sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 26213.17sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25152.65sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-base_template_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 29187.10sentences/s]\n","Reading Hurtlex: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 24103.70sentences/s]\n","Reading Perspective: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 25190.50sentences/s]\n"]},{"name":"stdout","output_type":"stream","text":["vinai/bertweet-large_template_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Reading Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8268/8268 [00:00<00:00, 28849.54sentences/s]\n"]},{"ename":"TypeError","evalue":"can only concatenate str (not \"NoneType\") to str","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m Evaluators(m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#prendo i valori di quel modello\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m eval_sent \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49msentiment_analysis_graph()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m eval_hurt \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mhurtlex_graph()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m eval_pers \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mperspective_graph()\n","\u001b[1;32m/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m df\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mNon Queer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m append_afinn_score(non_queer, non_queer_vec)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m#display(df)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(RESULTS_PATH\u001b[39m+\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_afinn.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mae/Documents/GitHub/QueerBench/src/queer_results.ipynb#X16sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mloc[:,\u001b[39m\"\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m\"\u001b[39m]\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"]}],"source":["sent_queer, sent_non, hurt_queer, hurt_non, persp_queer, persp_non, tot_queer, tot_non = [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_queer.append(truncate_float(eval_sent['Queer'],2))\n","    sent_non.append(truncate_float(eval_sent['Non Queer'],2))\n","    hurt_queer.append(truncate_float(eval_hurt['Queer'],2))\n","    hurt_non.append(truncate_float(eval_hurt['Non Queer'],2))\n","    persp_queer.append(truncate_float(eval_pers['Queer'],2))\n","    persp_non.append(truncate_float(eval_pers['Non Queer'],2))\n","    #print(eval_sent['Queer'])\n","    #print(trasforma_sentiment_score(eval_sent['Queer']))\n","    tot_queer.append(truncate_float(total_score(eval_sent['Queer'], eval_hurt['Queer'], eval_pers['Queer']),2)) \n","    tot_non.append(truncate_float(total_score(eval_sent['Non Queer'], eval_hurt['Non Queer'], eval_pers['Non Queer']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES)\n","df.loc['Sentiment queer'] = sent_queer\n","df.loc['Sentiment non queer'] = sent_non\n","df.loc['Hurtlex queer'] = hurt_queer\n","df.loc['Hurtlex non queer'] = hurt_non\n","df.loc['Perspective queer'] = persp_queer\n","df.loc['Perspective non queer'] = persp_non\n","df.loc['Total queer'] = tot_queer\n","df.loc['Total non queer'] = tot_non\n","#display(df)\n","df.to_csv(RESULTS_PATH+'total_score_term.csv', sep=';', index=True)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Pronouns total score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sent_neo, sent_neut, sent_bin, hurt_neo, hurt_neut, hurt_bin, persp_neo, persp_neut, persp_bin, tot_neo, tot_neut, tot_bin = [], [], [], [], [], [], [], [], [], [], [], []\n","#scorro i modelli\n","for m in MODELS:\n","    eval = Evaluators(m)\n","    #prendo i valori di quel modello\n","    eval_sent = eval.sentiment_analysis_graph()\n","    eval_hurt = eval.hurtlex_graph()\n","    eval_pers = eval.perspective_graph()\n","    #metto il valore di quel modello nelle righe\n","    sent_neo.append(truncate_float(eval_sent['Neo'],2))\n","    sent_neut.append(truncate_float(eval_sent['Neutral'],2))\n","    sent_bin.append(truncate_float(eval_sent['Binary'],2))\n","    hurt_neo.append(truncate_float  (eval_hurt['Neo'],2))\n","    hurt_neut.append(truncate_float (eval_hurt['Neutral'],2))\n","    hurt_bin.append(truncate_float  (eval_hurt['Binary'],2))\n","    persp_neo.append(truncate_float  (eval_pers['Neo'],2))\n","    persp_neut.append(truncate_float (eval_pers['Neutral'],2))\n","    persp_bin.append(truncate_float  (eval_pers['Binary'],2))\n","    tot_neo.append(truncate_float  (total_score(eval_sent['Neo'], eval_hurt['Neo'], eval_pers['Neo']),2))\n","    tot_neut.append(truncate_float  (total_score(eval_sent['Neutral'], eval_hurt['Neutral'], eval_pers['Neutral']),2)) \n","    tot_bin.append(truncate_float  (total_score(eval_sent['Binary'], eval_hurt['Binary'], eval_pers['Binary']),2))\n","df = pd.DataFrame(columns=MODELS_NAMES, )\n","df.loc['Sentiment Neo'] = sent_neo\n","df.loc['Sentiment Neutral'] = sent_neut\n","df.loc['Sentiment Binary'] = sent_bin\n","df.loc['Hurtlex Neo'] = hurt_neo\n","df.loc['Hurtlex Neutral'] = hurt_neut\n","df.loc['Hurtlex Binary'] = hurt_bin\n","df.loc['Perspective Neo'] = persp_neo\n","df.loc['Perspective Neutral'] = persp_neut\n","df.loc['Perspective Binary'] = persp_bin\n","df.loc['Total Neo'] = tot_neo\n","df.loc['Total Neutral'] = tot_neut\n","df.loc['Total Binary'] = tot_bin\n","display(df)\n","df.to_csv(RESULTS_PATH+'total_score_pronouns.csv', sep=';', index=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
