{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoModelForCausalLM , AutoTokenizer, pipeline, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertModel, AlbertForMaskedLM\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from afinn import Afinn\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "from time import sleep\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAC Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTITIES = 'identities'\n",
    "ORIENTATION = 'orientation'\n",
    "OTHER = 'other'\n",
    "PRONOUNS = 'pronouns'\n",
    "MASKBERT_ = '\\[MASK\\]'\n",
    "MASKBERT= '[MASK]'\n",
    "MASKROBERT = '<mask>'\n",
    "TARGET = '<target>'\n",
    "NOM = '<nom>'\n",
    "ACC = '<acc>'\n",
    "BE = '<be>'\n",
    "QUEER = 'queer'\n",
    "NONQUEER = 'non-queer'\n",
    "\n",
    "#TEMPLATES\n",
    "TEMPLATE_NOZZA = '../src/templates/template_nozza.csv'\n",
    "TEMPLATE_TOXIC1 = '../src/templates/template_toxing1.csv'\n",
    "TEMPLATE_TOXIC2 = '../src/templates/template_toxing2.csv'\n",
    "\n",
    "#IDENTITIES CSV\n",
    "IDENTITIES_CSV = '../src/queer_identities/identities.csv'\n",
    "PRONOUNS_CSV = '../src/queer_identities/pronouns.csv'\n",
    "\n",
    "#MODELS\n",
    "BERT_BASE = 'bert-base-uncased'\n",
    "BERT_LARGE = 'bert-large-uncased'\n",
    "ROBERTA_BASE = 'roberta-base'\n",
    "ROBERTA_LARGE = 'roberta-large'\n",
    "GPT2 = 'gpt2'\n",
    "ALBERT = 'albert-base-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(model_name):\n",
    "    if((model_name == BERT_BASE) or (model_name == BERT_LARGE)):\n",
    "        model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    else:\n",
    "        if(model_name == ALBERT):\n",
    "            tokenizer = AlbertTokenizer.from_pretrained(ALBERT)\n",
    "            model = AlbertForMaskedLM.from_pretrained(ALBERT)\n",
    "        else:\n",
    "            if((model_name == ROBERTA_BASE) or (model_name == ROBERTA_LARGE)):\n",
    "                model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "                tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "            else: \n",
    "                if(model_name == GPT2):\n",
    "                    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "                    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queer Bench class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueerBench():\n",
    "    def __init__(self, template_path, model_name, numAtt):\n",
    "        self.numAtt = numAtt\n",
    "        self.data = []\n",
    "        self.template_path = template_path\n",
    "        self.template_file = pd.read_csv(template_path, sep=\";\")\n",
    "        self.template_identities = pd.read_csv(IDENTITIES_CSV, sep=';')\n",
    "        self.template_pronouns = pd.read_csv(PRONOUNS_CSV, sep=';')\n",
    "        self.model_name = model_name\n",
    "        self.model, self.tokenizer = get_tokenizer(model_name)\n",
    "        self.template_builder()\n",
    "    \n",
    "    def template_builder(self):\n",
    "        if(self.template_path == TEMPLATE_NOZZA):\n",
    "            self.template_nozza()\n",
    "        else:\n",
    "            if (self.template_path == TEMPLATE_TOXIC1):\n",
    "                self.template_toxic1()\n",
    "        #     else: \n",
    "        #         self.template_toxic2()\n",
    "        \n",
    "    def template_nozza(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, r in self.template_identities.iterrows():\n",
    "                adjectiveList = []\n",
    "                _sentence = re.sub(TARGET, f\"The {r.loc['identity']} person\", sentence)\n",
    "                adjectiveList = self.predict_masked_sent(_sentence)\n",
    "                sentencesNew = []\n",
    "                for a in adjectiveList:\n",
    "                    #print(a)\n",
    "                    comp_sentence = re.sub(MASKBERT_, a, _sentence)\n",
    "                    comp_sentence = re.sub(BE, 'is', comp_sentence)\n",
    "                    sentencesNew.append(comp_sentence)  \n",
    "                    #print(comp_sentence)                              \n",
    "                data=[\n",
    "                    sentence, #template\n",
    "                    r.loc[\"identity\"], #identity\n",
    "                    adjectiveList, #word list\n",
    "                    sentencesNew, #sentence list\n",
    "                    r.loc[\"type\"] #type identity\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "            for ind, r in self.template_pronouns.iterrows():\n",
    "                adjectiveList = []\n",
    "                _sentence = re.sub(TARGET, r.loc[\"nom\"], sentence)\n",
    "                adjectiveList = self.predict_masked_sent(_sentence)\n",
    "                sentencesNew = []\n",
    "                for a in adjectiveList:\n",
    "                    comp_sentence = re.sub(MASKBERT_, a, _sentence)\n",
    "                    comp_sentence = re.sub(BE, r.loc[\"be\"], comp_sentence)\n",
    "                    sentencesNew.append(comp_sentence)\n",
    "                    #print(comp_sentence)                                         \n",
    "                data=[\n",
    "                    sentence, #template\n",
    "                    r.loc[\"nom\"], #identity\n",
    "                    r.loc[\"type\"], #type identity\n",
    "                    adjectiveList, #word list\n",
    "                    sentencesNew, #sentence list\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", \"identity\", \"type\", \"attributes\", \"sentences\"])\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "    \n",
    "    def template_toxic1(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, identity in self.template_identities.iterrows():\n",
    "                adjectiveList = []\n",
    "                _sentence = re.sub(TARGET, f\"The {identity.loc['identity']} person\", sentence)\n",
    "                for id, pronouns in self.template_pronouns.iterrows():\n",
    "                    __sentence = re.sub(NOM, pronouns.loc['nom'], _sentence)\n",
    "                    adjectiveList = self.predict_masked_sent(__sentence)\n",
    "                    sentencesNew = []\n",
    "                    for a in adjectiveList:\n",
    "                        #print(a)\n",
    "                        comp_sentence = re.sub(MASKBERT_, a, __sentence)\n",
    "                        comp_sentence = re.sub(BE, pronouns.loc['be'], comp_sentence)\n",
    "                        sentencesNew.append(comp_sentence)  \n",
    "                        #print(comp_sentence)                              \n",
    "                    data=[\n",
    "                        sentence, #template\n",
    "                        identity.loc[\"identity\"], #identity\n",
    "                        adjectiveList, #word list\n",
    "                        sentencesNew, #sentence list\n",
    "                        identity.loc[\"type\"], #type identity\n",
    "                        pronouns.loc[\"nom\"], #pronouns nom\n",
    "                        pronouns.loc[\"type\"] #type pronouns\n",
    "                    ]\n",
    "                    dataList.append(data) \n",
    "            for ind, pronouns in self.template_pronouns.iterrows():\n",
    "                adjectiveList = []\n",
    "                _sentence = re.sub(TARGET, pronouns.loc[\"nom\"], sentence)\n",
    "                adjectiveList = self.predict_masked_sent(_sentence)\n",
    "                sentencesNew = []\n",
    "                for a in adjectiveList:\n",
    "                    comp_sentence = re.sub(MASKBERT_, a, _sentence)\n",
    "                    comp_sentence = re.sub(BE, pronouns.loc[\"be\"], comp_sentence)\n",
    "                    sentencesNew.append(comp_sentence)\n",
    "                    #print(comp_sentence)                                         \n",
    "                data=[\n",
    "                    sentence, #template\n",
    "                    pronouns.loc[\"nom\"], #identity\n",
    "                    pronouns.loc[\"type\"], #type identity\n",
    "                    adjectiveList, #word list\n",
    "                    sentencesNew, #sentence list\n",
    "                    pronouns.loc[\"nom\"], #pronouns nom\n",
    "                    pronouns.loc[\"type\"] #type pronouns\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", \"identity\", \"type_identity\", \"attributes\", \"sentences\", \"nom_identity\", ])\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "\n",
    "    def predict_masked_sent(self, text):\n",
    "        if((self.model_name == BERT_BASE) or (self.model_name == BERT_LARGE) or (self.model_name== ALBERT)):\n",
    "            text = \"[CLS] %s [SEP]\"%text\n",
    "            #print(text)\n",
    "            tokenized_text = self.tokenizer.tokenize(text)\n",
    "            masked_index = tokenized_text.index(MASKBERT)\n",
    "            indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            tokens_tensor = torch.tensor([indexed_tokens])\n",
    "            with torch.no_grad():\n",
    "                output = self.model(tokens_tensor)\n",
    "                predictions = output[0]\n",
    "\n",
    "            probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "            top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "            adjectiveList = []\n",
    "            for i, pred_idx in enumerate(top_k_indices):\n",
    "                predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "                token_weight = top_k_weights[i]\n",
    "                #print(predicted_token)\n",
    "                #print(token_weight.item()*100)\n",
    "                adjectiveList.append(predicted_token)\n",
    "            return adjectiveList\n",
    "        else:\n",
    "            if((self.model_name == ROBERTA_BASE) or (self.model_name == ROBERTA_LARGE)):\n",
    "                text = re.sub(MASKBERT_, MASKROBERT, text)\n",
    "                text = \"<s> %s </s>\"%text\n",
    "                #print(text)\n",
    "                tokenized_text = self.tokenizer.tokenize(text)\n",
    "                #print(tokenized_text)\n",
    "                masked_index = tokenized_text.index(MASKROBERT)\n",
    "                indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "                tokens_tensor = torch.tensor([indexed_tokens])\n",
    "                with torch.no_grad():\n",
    "                    output = self.model(tokens_tensor)\n",
    "                    predictions = output[0]\n",
    "\n",
    "                probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "                top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "                adjectiveList = []\n",
    "                for i, pred_idx in enumerate(top_k_indices):\n",
    "                    predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "                    predicted_token = re.sub('Ġ', '', predicted_token)\n",
    "                    token_weight = top_k_weights[i]\n",
    "                    print(predicted_token)\n",
    "                    print(token_weight.item()*100)\n",
    "                    adjectiveList.append(predicted_token)\n",
    "                return adjectiveList\n",
    "            else:\n",
    "                if(self.model_name == GPT2):\n",
    "                    inputs = self.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(inputs)\n",
    "                        predictions = outputs[0]\n",
    "                    next_token_candidates_tensor = predictions[0, -1, :]\n",
    "                    topk_candidates_indexes = torch.topk(next_token_candidates_tensor, self.numAtt).indices.tolist()\n",
    "                    #all_candidates_probabilities = torch.nn.functional.softmax(next_token_candidates_tensor, dim=-1)\n",
    "                    #topk_candidates_probabilities = all_candidates_probabilities[topk_candidates_indexes].tolist()\n",
    "                    topk_candidates_tokens = [self.tokenizer.decode([idx]).strip() for idx in topk_candidates_indexes]\n",
    "                    return list(topk_candidates_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select template: TEMPLATE_NOZZA, TEMPLATE_TOXIC1, TEMPLATE_TOXIC2\n",
    "#Select model: BERT_BASE, BERT_LARGE, ROBERTA_BASE, ROBERTA_LARGE, GPT2, ALBERT\n",
    "BenchNozza = QueerBench(TEMPLATE_TOXIC1, BERT_BASE, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
