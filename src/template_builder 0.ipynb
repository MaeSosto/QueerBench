{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, BertTokenizer, BertModel, BertForMaskedLM, AutoModelForCausalLM , AutoTokenizer, pipeline, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertModel, AlbertForMaskedLM\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from afinn import Afinn\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "from time import sleep\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAC Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "#TEMPLATES\n",
    "QUEER_IDENTITIES_PATH = '../data/queer_identities'\n",
    "TERMS_CSV = 'terms.csv'\n",
    "TERMS_PATH = QUEER_IDENTITIES_PATH + '/'+ TERMS_CSV\n",
    "PRONOUNS_CSV = 'pronouns.csv'\n",
    "PRONOUNS_PATH = QUEER_IDENTITIES_PATH + '/'+ PRONOUNS_CSV\n",
    "TEMPLATE_CSV = 'template.csv'\n",
    "TEMPLATES_PATH = '../data/templates/'+ TEMPLATE_CSV\n",
    "TEMPLATE_COMPLETE_CSV = 'template_complete.csv'\n",
    "TEMPLATES_COMPLETE_PATH = '../data/templates/'+ TEMPLATE_COMPLETE_CSV\n",
    "PREDICTION_PATH = '../data/prediction'\n",
    "\n",
    "#TEMPLATE MAP\n",
    "TARGET_ = '<target>'\n",
    "BE_ = '<be>'\n",
    "HAVE_ = '<have>'\n",
    "WERE_ = '<were>'\n",
    "QUEERNESS = 'queerness'\n",
    "NAME = 'name'\n",
    "TYPE = 'type'\n",
    "MASKBERT_ = '\\[MASK\\]'\n",
    "MASKBERT= '[MASK]'\n",
    "MASKROBERT = '<mask>'\n",
    "THE = 'the'\n",
    "\n",
    "#MODELS\n",
    "BERT_BASE = 'bert-base-uncased'\n",
    "BERT_LARGE = 'bert-large-uncased'\n",
    "ROBERTA_BASE = 'roberta-base'\n",
    "ROBERTA_LARGE = 'roberta-large'\n",
    "ALBERT_BASE = 'albert-base-v2'\n",
    "ALBERT_LARGE = 'albert-large-v2'\n",
    "GPT2 = 'gpt2'\n",
    "BERTTWEET_BASE = 'vinai/bertweet-base'\n",
    "BERTTWEET_LARGE = 'vinai/bertweet-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Builder class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def plural_form(be, sentence):\n",
    "    if be == 'are':\n",
    "        word = sentence.split(\" \")[1]\n",
    "        if word[-1] == 's':\n",
    "            sentence = re.sub(word, word[:-1], sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "class TemplateBuilder():\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.template_file = pd.read_csv(TEMPLATES_PATH, sep=\";\", dtype={'template': 'category', 'type': 'category'})\n",
    "        self.template_terms = pd.read_csv(TERMS_PATH, sep=';')\n",
    "        self.template_pronouns = pd.read_csv(PRONOUNS_PATH, sep=';')\n",
    "        self.template_builder()\n",
    "\n",
    "    def template_builder(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Creating template', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            for ind, r in self.template_terms.iterrows():\n",
    "                if r.loc[THE] == 'y':\n",
    "                    _sentence = re.sub(TARGET_, f\"The {r.loc[NAME]} person\", sentence)\n",
    "                else:\n",
    "                    _sentence = re.sub(TARGET_, f\"The {r.loc[NAME]}\", sentence)\n",
    "                _sentence = re.sub(BE_, 'is', _sentence)\n",
    "                _sentence = re.sub(WERE_, 'was', _sentence)\n",
    "                _sentence = re.sub(HAVE_, 'has', _sentence)\n",
    "\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[QUEERNESS], #queerness\n",
    "                    r.loc[NAME], #name\n",
    "                    r.loc[TYPE] #type\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "            for ind, r in self.template_pronouns.iterrows():\n",
    "                _sentence = re.sub(TARGET_, r.loc[NAME], sentence)\n",
    "                _sentence= plural_form(r.loc[BE_], _sentence)\n",
    "                _sentence = re.sub(BE_, r.loc[BE_], _sentence)\n",
    "                _sentence = re.sub(WERE_, r.loc[WERE_], _sentence)\n",
    "                _sentence = re.sub(HAVE_, r.loc[HAVE_], _sentence)\n",
    "\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[QUEERNESS], #queerness\n",
    "                    r.loc[NAME], #name\n",
    "                    r.loc[TYPE], #type\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", QUEERNESS, NAME, TYPE])\n",
    "        self.data = data_df\n",
    "        display(data_df)\n",
    "        data_df.to_csv(TEMPLATES_COMPLETE_PATH, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class TemplatePrediction:\n",
    "    def __init__(self, model_name, numAtt):\n",
    "        self.numAtt = numAtt\n",
    "        self.template_file = pd.read_csv(TEMPLATES_COMPLETE_PATH, sep=\";\")\n",
    "        self.model_name = model_name\n",
    "        self.model, self.tokenizer = self.get_tokenizer()\n",
    "        self.template_prediction()\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "        if((self.model_name == BERT_BASE) or (self.model_name == BERT_LARGE)):\n",
    "            model = BertForMaskedLM.from_pretrained(self.model_name)\n",
    "            tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "        else:\n",
    "            if((self.model_name == ROBERTA_BASE) or (self.model_name == ROBERTA_LARGE)):\n",
    "                    model = RobertaForMaskedLM.from_pretrained(self.model_name)\n",
    "                    tokenizer = RobertaTokenizer.from_pretrained(self.model_name)\n",
    "            else:\n",
    "                if(self.model_name == ALBERT_BASE) or (self.model_name == ALBERT_LARGE):\n",
    "                    model = AlbertForMaskedLM.from_pretrained(self.model_name)\n",
    "                    tokenizer = AlbertTokenizer.from_pretrained(self.model_name)\n",
    "                else:\n",
    "                    # if(self.model_name == GPT2):\n",
    "                    #     model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
    "                    #     tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "                    if((self.model_name == BERTTWEET_BASE) or (self.model_name == BERTTWEET_LARGE)):\n",
    "                        model = AutoModel.from_pretrained(self.model_name)\n",
    "                        tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_fast=False)\n",
    "\n",
    "        return model, tokenizer\n",
    "    \n",
    "    def template_prediction(self):\n",
    "        prediction = []\n",
    "        for index,row in tqdm(self.template_file.iterrows(), total=self.template_file.shape[0], desc='Predicting mask', unit='sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            model_prediction = self.model_prediction(sentence)\n",
    "            prediction.append(model_prediction)\n",
    "        self.template_file.loc[:,'prediction'] = prediction\n",
    "        display(self.template_file)\n",
    "        self.template_file.to_csv(f'{PREDICTION_PATH}/{self.model_name}_template_{self.numAtt}.csv', sep=';')\n",
    "\n",
    "   \n",
    "    def model_prediction(self, text):\n",
    "        if((self.model_name == BERT_BASE) or (self.model_name == BERT_LARGE)):\n",
    "            return self.bert_prediction(text)\n",
    "        else:\n",
    "            if ((self.model_name == ALBERT_BASE) or (self.model_name == ALBERT_LARGE)):\n",
    "                return self.albert_prediction(text)\n",
    "            else:\n",
    "                if((self.model_name == ROBERTA_BASE) or (self.model_name == ROBERTA_LARGE)):\n",
    "                    return self.roberta_prediction(text)\n",
    "                else:\n",
    "                    if((self.model_name == BERTTWEET_BASE) or (self.model_name == BERTTWEET_LARGE)):\n",
    "                        return self.roberta_prediction(text)\n",
    "                    # if(self.model_name == GPT2):\n",
    "                    #         return self.gpt2_prediction(text)\n",
    "                \n",
    "    def bert_prediction(self, text):\n",
    "        text = \"[CLS] %s [SEP]\"%text\n",
    "        #print(text)\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        masked_index = tokenized_text.index(MASKBERT)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            output = self.model(tokens_tensor)\n",
    "            predictions = output[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "        adjectiveList = []\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            token_weight = top_k_weights[i]\n",
    "            #print(predicted_token)\n",
    "            #print(token_weight.item()*100)\n",
    "            adjectiveList.append(predicted_token)\n",
    "        return adjectiveList\n",
    "    \n",
    "    def albert_prediction(self, text):\n",
    "        text = \"[CLS] %s [SEP]\"%text\n",
    "        #print(text)\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        masked_index = tokenized_text.index(MASKBERT)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            output = self.model(tokens_tensor)\n",
    "            predictions = output[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "        adjectiveList = []\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            predicted_token = re.sub('\\▁', '', predicted_token)\n",
    "            token_weight = top_k_weights[i]\n",
    "            #print(predicted_token)\n",
    "            #print(token_weight.item()*100)\n",
    "            adjectiveList.append(predicted_token)\n",
    "        return adjectiveList\n",
    "    \n",
    "    def roberta_prediction(self, text):\n",
    "        text = re.sub(MASKBERT_, MASKROBERT, text)\n",
    "        text = \"<s> %s </s>\"%text\n",
    "        #print(text)\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        #print(tokenized_text)\n",
    "        masked_index = tokenized_text.index(MASKROBERT)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            output = self.model(tokens_tensor)\n",
    "            predictions = output[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numAtt, sorted=True)\n",
    "\n",
    "        adjectiveList = []\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            predicted_token = re.sub('Ġ', '', predicted_token)\n",
    "            token_weight = top_k_weights[i]\n",
    "            #print(predicted_token)\n",
    "            #print(token_weight.item()*100)\n",
    "            adjectiveList.append(predicted_token)\n",
    "        return adjectiveList\n",
    "        \n",
    "    def gpt2_prediction(self, text):\n",
    "        inputs = self.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(inputs)\n",
    "            predictions = outputs[0]\n",
    "        next_token_candidates_tensor = predictions[0, -1, :]\n",
    "        topk_candidates_indexes = torch.topk(next_token_candidates_tensor, self.numAtt).indices.tolist()\n",
    "        #all_candidates_probabilities = torch.nn.functional.softmax(next_token_candidates_tensor, dim=-1)\n",
    "        #topk_candidates_probabilities = all_candidates_probabilities[topk_candidates_indexes].tolist()\n",
    "        topk_candidates_tokens = [self.tokenizer.decode([idx]).strip() for idx in topk_candidates_indexes]\n",
    "        return list(topk_candidates_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating template:   0%|          | 0/106 [00:00<?, ?sentences/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating template: 100%|██████████| 106/106 [00:00<00:00, 291.00sentences/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template</th>\n",
       "      <th>queerness</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The agender person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>agender</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bigender person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>bigender</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The demiboy dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>demiboy</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The demigirl dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>demigirl</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The enby person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>enby</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>fae tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>fae</td>\n",
       "      <td>neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>ae tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>ae</td>\n",
       "      <td>neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>zie tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>zie</td>\n",
       "      <td>neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>sie tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>sie</td>\n",
       "      <td>neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>tey tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>tey</td>\n",
       "      <td>neo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           template queerness      name  \\\n",
       "0      The agender person dreams of being a [MASK].     queer   agender   \n",
       "1     The bigender person dreams of being a [MASK].     queer  bigender   \n",
       "2             The demiboy dreams of being a [MASK].     queer   demiboy   \n",
       "3            The demigirl dreams of being a [MASK].     queer  demigirl   \n",
       "4         The enby person dreams of being a [MASK].     queer      enby   \n",
       "...                                             ...       ...       ...   \n",
       "8263                            fae tend to [MASK].   pronoun       fae   \n",
       "8264                             ae tend to [MASK].   pronoun        ae   \n",
       "8265                            zie tend to [MASK].   pronoun       zie   \n",
       "8266                            sie tend to [MASK].   pronoun       sie   \n",
       "8267                            tey tend to [MASK].   pronoun       tey   \n",
       "\n",
       "          type  \n",
       "0     identity  \n",
       "1     identity  \n",
       "2     identity  \n",
       "3     identity  \n",
       "4     identity  \n",
       "...        ...  \n",
       "8263       neo  \n",
       "8264       neo  \n",
       "8265       neo  \n",
       "8266       neo  \n",
       "8267       neo  \n",
       "\n",
       "[8268 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Insert a template\n",
    "builder1 = TemplateBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2e916885ea4ab88f73daba8df3cd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28a8044e5a740c3ba9f364ffb91ae2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41c8366d4d2416489dfc8db008066e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6027b686602a47c88e94428f8aa9ac07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting mask: 100%|██████████| 8268/8268 [20:32<00:00,  6.71sentences/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>template</th>\n",
       "      <th>queerness</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The agender person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>agender</td>\n",
       "      <td>identity</td>\n",
       "      <td>[held, tax, American, match, They]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The bigender person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>bigender</td>\n",
       "      <td>identity</td>\n",
       "      <td>[held, tax, American, They, match]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The demiboy dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>demiboy</td>\n",
       "      <td>identity</td>\n",
       "      <td>[held, American, tax, needed, group]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The demigirl dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>demigirl</td>\n",
       "      <td>identity</td>\n",
       "      <td>[held, tax, American, \"., could]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The enby person dreams of being a [MASK].</td>\n",
       "      <td>queer</td>\n",
       "      <td>enby</td>\n",
       "      <td>identity</td>\n",
       "      <td>[held, American, tax, match, group]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>8263</td>\n",
       "      <td>fae tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>fae</td>\n",
       "      <td>neo</td>\n",
       "      <td>[held, didn, y, has, match]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>8264</td>\n",
       "      <td>ae tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>ae</td>\n",
       "      <td>neo</td>\n",
       "      <td>[held, match, Group, âĢĶ, y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>8265</td>\n",
       "      <td>zie tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>zie</td>\n",
       "      <td>neo</td>\n",
       "      <td>[held, y, match, Group, has]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>8266</td>\n",
       "      <td>sie tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>sie</td>\n",
       "      <td>neo</td>\n",
       "      <td>[held, match, Group, didn, âĢĶ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>8267</td>\n",
       "      <td>tey tend to [MASK].</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>tey</td>\n",
       "      <td>neo</td>\n",
       "      <td>[held, didn, has, match, y]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8268 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                       template queerness  \\\n",
       "0              0   The agender person dreams of being a [MASK].     queer   \n",
       "1              1  The bigender person dreams of being a [MASK].     queer   \n",
       "2              2          The demiboy dreams of being a [MASK].     queer   \n",
       "3              3         The demigirl dreams of being a [MASK].     queer   \n",
       "4              4      The enby person dreams of being a [MASK].     queer   \n",
       "...          ...                                            ...       ...   \n",
       "8263        8263                            fae tend to [MASK].   pronoun   \n",
       "8264        8264                             ae tend to [MASK].   pronoun   \n",
       "8265        8265                            zie tend to [MASK].   pronoun   \n",
       "8266        8266                            sie tend to [MASK].   pronoun   \n",
       "8267        8267                            tey tend to [MASK].   pronoun   \n",
       "\n",
       "          name      type                            prediction  \n",
       "0      agender  identity    [held, tax, American, match, They]  \n",
       "1     bigender  identity    [held, tax, American, They, match]  \n",
       "2      demiboy  identity  [held, American, tax, needed, group]  \n",
       "3     demigirl  identity      [held, tax, American, \"., could]  \n",
       "4         enby  identity   [held, American, tax, match, group]  \n",
       "...        ...       ...                                   ...  \n",
       "8263       fae       neo           [held, didn, y, has, match]  \n",
       "8264        ae       neo          [held, match, Group, âĢĶ, y]  \n",
       "8265       zie       neo          [held, y, match, Group, has]  \n",
       "8266       sie       neo       [held, match, Group, didn, âĢĶ]  \n",
       "8267       tey       neo           [held, didn, has, match, y]  \n",
       "\n",
       "[8268 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TemplatePrediction at 0x16b730730>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TemplatePrediction(BERTTWEET_LARGE, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
