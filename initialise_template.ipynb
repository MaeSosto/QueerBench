{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install transformers\n",
    "!pip install sentencepiece\n",
    "!pip3 install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, BertTokenizer, BertForMaskedLM, AutoTokenizer, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertForMaskedLM\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Source\n",
    "DATA_SOURCE = 'dataset_source/'\n",
    "OUTPUT_TEMPLATE = 'output_template/'\n",
    "OUTPUT_PREDICTION = 'output_prediction/'\n",
    "TEMPLATE_PATH = DATA_SOURCE + 'template.csv'\n",
    "NOUNS_PATH = DATA_SOURCE + 'nouns.csv'\n",
    "PRONOUNS_PATH = DATA_SOURCE + 'pronouns.csv'\n",
    "TEMPLATES_COMPLETE_PATH = OUTPUT_TEMPLATE + 'template_complete.csv'\n",
    "\n",
    "# TEMPLATE MAP\n",
    "TARGET_ = '<target>'\n",
    "BE_ = '<be>'\n",
    "HAVE_ = '<have>'\n",
    "WERE_ = '<were>'\n",
    "QUEERNESS = 'queerness'\n",
    "TYPE = 'type'\n",
    "CATEGORY= 'category'\n",
    "SUBJECT = 'subject'\n",
    "MASKBERT_ = '\\[MASK\\]'\n",
    "MASKBERT = '[MASK]'\n",
    "MASKROBERT = '<mask>'\n",
    "THE = 'the'\n",
    "\n",
    "# MODELS\n",
    "MODELS = {\n",
    "    'BERT_base': 'bert-base-uncased',\n",
    "    'BERT_large': 'bert-large-uncased',\n",
    "    'RoBERTa_base': 'roberta-base',\n",
    "    'RoBERTa_large': 'roberta-large',\n",
    "    'AlBERT_base': 'albert-base-v2',\n",
    "    'AlBERT_large': 'albert-large-v2',\n",
    "    'BERTweet_base': 'vinai/bertweet-base',\n",
    "    'BERTweet_large': 'vinai/bertweet-large'\n",
    "}\n",
    "\n",
    "BERT_BASE = 'BERT_base'\n",
    "BERT_LARGE = 'BERT_large'\n",
    "ROBERTA_BASE = 'RoBERTa_base'\n",
    "ROBERTA_LARGE = 'RoBERTa_large'\n",
    "ALBERT_BASE = 'AlBERT_base'\n",
    "ALBERT_LARGE = 'AlBERT_large'\n",
    "BERTTWEET_BASE = 'BERTweet_base'\n",
    "BERTTWEET_LARGE = 'BERTweet_large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Complete Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteTemplateBuilder():\n",
    "    def __init__(self):\n",
    "        self.template = pd.read_csv(TEMPLATE_PATH, sep=\";\", dtype={'template': 'category', 'category': 'category'})\n",
    "        self.nouns = pd.read_csv(NOUNS_PATH, sep=';')\n",
    "        self.pronouns = pd.read_csv(PRONOUNS_PATH, sep=';')\n",
    "        self.template_builder()\n",
    "\n",
    "    def plural_form(self, be, sentence):\n",
    "        if be == 'are':\n",
    "            word = sentence.split(\" \")[1]\n",
    "            if word[-1] == 's':\n",
    "                sentence = sentence.replace(word, word[:-1])\n",
    "        return sentence\n",
    "\n",
    "    def template_builder(self):\n",
    "        dataList =[]\n",
    "        for index,row in tqdm(self.template.iterrows(), total=self.template.shape[0], desc='Creating template', unit=' sentences'):\n",
    "            sentence = row.loc['template']\n",
    "            \n",
    "            #Creating sentences with nouns\n",
    "            for ind, r in self.nouns.iterrows():\n",
    "                _sentence = sentence.replace(TARGET_, f\"The {r.loc[SUBJECT]} person\") if r.loc[THE] == 'y' else sentence.replace(TARGET_, f\"The {r.loc[SUBJECT]}\")\n",
    "                _sentence = _sentence.replace(BE_, 'is').replace(WERE_, 'was').replace(HAVE_, 'has')\n",
    "\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[TYPE], #type\n",
    "                    r.loc[CATEGORY], #category\n",
    "                    r.loc[SUBJECT] #subject\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "\n",
    "            #Creating sentences with pronouns\n",
    "            for ind, r in self.pronouns.iterrows():\n",
    "                _sentence= self.plural_form(r.loc[BE_], sentence.replace(TARGET_, r.loc[SUBJECT]))\n",
    "                _sentence = _sentence.replace(BE_, r.loc[BE_]).replace(WERE_, r.loc[WERE_]).replace(HAVE_, r.loc[HAVE_])\n",
    "\n",
    "                data=[\n",
    "                    _sentence, #new template\n",
    "                    r.loc[TYPE], #type\n",
    "                    r.loc[CATEGORY], #category\n",
    "                    r.loc[SUBJECT] #subject\n",
    "                ]\n",
    "                dataList.append(data) \n",
    "        data_df = pd.DataFrame(dataList, columns=[\"template\", TYPE, CATEGORY, SUBJECT])\n",
    "        display(data_df)\n",
    "        os.makedirs(OUTPUT_TEMPLATE, exist_ok=True)\n",
    "        data_df.to_csv(TEMPLATES_COMPLETE_PATH, sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplatePrediction:\n",
    "    def __init__(self, modelName, numPrediction):\n",
    "        self.numPrediction = numPrediction\n",
    "        self.modelName = modelName\n",
    "        self.templateFile = pd.read_csv(TEMPLATES_COMPLETE_PATH, sep=\";\")\n",
    "        self.model, self.tokenizer = self.getModelTokenizer()\n",
    "        self.getPredictions()\n",
    "\n",
    "    def getModelTokenizer(self):\n",
    "        if((self.modelName == BERT_BASE) or (self.modelName == BERT_LARGE)):\n",
    "            return BertForMaskedLM.from_pretrained(MODELS[self.modelName]), BertTokenizer.from_pretrained(MODELS[self.modelName])\n",
    "        elif((self.modelName == ROBERTA_BASE) or (self.modelName == ROBERTA_LARGE)):\n",
    "            return RobertaForMaskedLM.from_pretrained(MODELS[self.modelName]), RobertaTokenizer.from_pretrained(MODELS[self.modelName])\n",
    "        elif(self.modelName == ALBERT_BASE) or (self.modelName == ALBERT_LARGE):\n",
    "            return AlbertForMaskedLM.from_pretrained(MODELS[self.modelName]), AlbertTokenizer.from_pretrained(MODELS[self.modelName])\n",
    "        elif((self.modelName == BERTTWEET_BASE) or (self.modelName == BERTTWEET_LARGE)):\n",
    "            return AutoModel.from_pretrained(MODELS[self.modelName]), AutoTokenizer.from_pretrained(MODELS[self.modelName], use_fast=False)\n",
    "    \n",
    "\n",
    "    def getWordPrediction(self, text):\n",
    "        if ((self.modelName == BERT_BASE) or (self.modelName == BERT_LARGE) or (self.modelName == ALBERT_BASE) or (self.modelName == ALBERT_LARGE)):\n",
    "            text = \"[CLS] %s [SEP]\"%text\n",
    "            tokenized_text = self.tokenizer.tokenize(text)\n",
    "            masked_index = tokenized_text.index(MASKBERT)\n",
    "        else:\n",
    "            text = text.replace(MASKBERT, MASKROBERT)\n",
    "            text = \"<s> %s </s>\"%text\n",
    "            tokenized_text = self.tokenizer.tokenize(text)\n",
    "            masked_index = tokenized_text.index(MASKROBERT)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            output = self.model(tokens_tensor)\n",
    "            predictions = output[0]\n",
    "\n",
    "        probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.numPrediction, sorted=True)\n",
    "\n",
    "        adjectiveList = []\n",
    "        for i, pred_idx in enumerate(top_k_indices):\n",
    "            predicted_token = self.tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "            if ((self.modelName == ALBERT_BASE) or (self.modelName == ALBERT_LARGE)):\n",
    "                predicted_token = predicted_token.replace(r'▁', '')\n",
    "            elif ((self.modelName == ROBERTA_BASE) or (self.modelName == ROBERTA_LARGE) or (self.modelName == BERTTWEET_BASE) or (self.modelName == BERTTWEET_LARGE)):\n",
    "                predicted_token = predicted_token.replace('Ġ', '')\n",
    "            adjectiveList.append(predicted_token)\n",
    "        return adjectiveList\n",
    "\n",
    "    def getPredictions(self):\n",
    "        prediction = []\n",
    "        for index,row in tqdm(self.templateFile.iterrows(), total=self.templateFile.shape[0], desc=f'Predicting mask with {self.modelName} in top-{self.numPrediction}', unit='sentences'):\n",
    "            model_prediction = self.getWordPrediction(row.loc['template'])\n",
    "            prediction.append(model_prediction)\n",
    "        self.templateFile.loc[:,'prediction'] = prediction\n",
    "        os.makedirs(OUTPUT_PREDICTION, exist_ok=True)\n",
    "        self.templateFile.to_csv(f'{OUTPUT_PREDICTION}/{self.modelName}_{self.numPrediction}.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete template\n",
    "#CompleteTemplateBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: model, number of predictions\n",
    "for i in range(len(MODELS)):\n",
    "    modelName = list(MODELS.keys())[i]\n",
    "    predictionNumber = 5\n",
    "    TemplatePrediction(modelName, predictionNumber)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
